{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChemBioSys and AquaDiva | Genome-resolved metagenomics workshop\n",
    "\n",
    "## Session 06 | Scalable pipelines \n",
    "\n",
    "Date: 18-19 September 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ‚ùì **Why do we need scalable pipelines?**\n",
    "**Disasdvantages of having stand alone tools:**\n",
    "\n",
    "1. Reproducibility: üí≠ Which version did i use?<br>\n",
    "<br>\n",
    "2. Data privacy: üíÄ Am i allowed to share that on a 'open server'?<br>\n",
    "<br>\n",
    "3. Efficiency: üíÇ‚Äç‚ôÇÔ∏è Large scale input and output?<br>\n",
    "<br>\n",
    "4. Standradisation: üëÄ Comparable output?<br>\n",
    "<br>\n",
    "5. Bioinformatics: üòπ Are my coding skills sufficient? Time?\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One example of scalable pipelines: [nf-core](https://nf-co.re/)\n",
    "\n",
    "\n",
    "<img src=\"img/nf-core-logo.png\" width=\"500\"/>\n",
    "<font size=\"2\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/nf-core-fig.png\" width=\"500\"/>\n",
    "<font size=\"2\"> \n",
    "\n",
    "<font size=\"2\">[Ewels et.al. 2020](https://www.nature.com/articles/s41587-020-0439-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A community effort to collect a curated set of analysis pipelines built using Nextflow to run tasks across multiple compute infrastructure.<br>\n",
    "<br>\n",
    "- Highly optimised pipelines\n",
    "- Portable (docker/singularity/conda)\n",
    "- Extensive documentation provided by the nf-core community\n",
    "- Reproducible due to validated releases and packaged software\n",
    "- Widespread community ready to help\n",
    "- Easy to apply and use\n",
    "\n",
    "---\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pipeline example**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/nf-core-funcscan_logo_flat_dark.png\" width=\"500\"/>\n",
    "<font size=\"2\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bioinformatics best-practice analysis pipeline for the screening of nucleotide sequences such as assembled contigs for functional genes. It currently features mining for antimicrobial peptides, antibiotic resistance genes and biosynthetic gene clusters.\n",
    "\n",
    "<img src=\"img/funcscan_metro_workflow.png\" width=\"500\"/>\n",
    "<font size=\"2\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example Usage**\n",
    "\n",
    "1. Prepare a samplesheet (samplesheet.csv) with your input data. Each row represents a (multi-)fasta file of assembled contig sequences.\n",
    "\n",
    "```\n",
    "sample,fasta\n",
    "CONTROL_REP1,AEG588A1_001.fasta\n",
    "CONTROL_REP2,AEG588A1_002.fasta\n",
    "CONTROL_REP3,AEG588A1_003.fasta\n",
    "```\n",
    "\n",
    "2.  Run the pipeline in a simple CLI line:\n",
    "\n",
    "```\n",
    "nextflow run nf-core/funcscan \\\n",
    "   -profile <docker/singularity/podman/shifter/charliecloud/conda/institute> \\\n",
    "   --input samplesheet.csv \\\n",
    "   --outdir <OUTDIR> \\\n",
    "   --run_amp_screening \\\n",
    "   --run_arg_screening \\\n",
    "   --run_bgc_screening\n",
    "```\n",
    "\n",
    "3. Output comprises of three csv tables corresponding to AMP - BGC - ARGs with which the user can filter further downstream.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">For more information please refer to [Funcscan documentation](https://github.com/nf-core/funcscan) \n",
    "</span>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snakemake\n",
    "`nf-core` is based on [`nextflow`](https://www.nextflow.io/), which is a workflow management system. In life sciences, scalable pipelines are currently mostly written using either `nextflow` or [`Snakemake`](https://snakemake.github.io/). \n",
    "\n",
    "#### In a nutshell\n",
    "`Snakemake` is a tool to create reproducible and scalable data analyses. Workflows are described via a human readable, [`Python`](https://www.python.org/) based language. They can be seamlessly scaled to server, cluster, grid and cloud environments, without the need to modify the workflow definition. Finally, `Snakemake` workflows can entail a description of required software, which will be automatically deployed to any execution environment.\n",
    "\n",
    "<img src=\"img/smk_1.png\" alt=\"Snakemake\" width=\"500\"/>\n",
    "\n",
    "#### Rules\n",
    "`Snakemake` is centered around rules that define input and output files, and how these files should be processed/generated. \n",
    "\n",
    "<img src=\"img/smk_2.png\" alt=\"Snakemake rules\" width=\"500\"/>\n",
    "\n",
    "#### Automatic depency inference\n",
    "`Snakemake` dynamically determined what rules have to be followed in order to generate the intended output. This means rules are connected by input/output files and `Snakemake` determines what files are already there. If a workflow was run before, stopped for whatever reason, and is repeated; `Snakemake` determines what output files are left to be generated and runs only the needed rules.\n",
    "\n",
    "<img src=\"img/smk_3.png\" alt=\"Snakemake rules\" width=\"500\"/>\n",
    "\n",
    "#### Scalability\n",
    "`Snakemake` workflows can run in any environment (locally, clusters, cloud).\n",
    "\n",
    "<img src=\"img/smk_4.png\" alt=\"Snakemake rules\" width=\"500\"/>\n",
    "\n",
    "#### Automatic software deployment\n",
    "Needed tools can be installed _on the fly_ through e.g. `conda` or [`docker`](https://www.docker.com/).\n",
    "\n",
    "<img src=\"img/smk_5.png\" alt=\"Snakemake rules\" width=\"500\"/>\n",
    "\n",
    "#### Nextflow vs. Snakemake\n",
    "`Nextflow` and `Snakemake` are both great tools and ultimately serve similar purposes, primarily making science more reproducible and making high-throughput data processing more accessible. `nf-core` is a big asset, as it provides numerous, well-documented pipelines. Overall, the `Nextflow` community is bigger than the `Snakemake` camp. `Snakemake` is heavily based on [`python`](https://www.python.org/), in comparison to `nextflow`, the learning curve with `Snakemake` is arguably üòú flatter. Within `Snakemake`, there is the [Snakemake Wrappers project](https://snakemake-wrappers.readthedocs.io/en/stable/), which is a collection of reusable wrappers that allow to quickly use popular tools from Snakemake rules and workflows. In the end, it comes down to personal preference.\n",
    "\n",
    "_Useful `Snakemake` resources:_\n",
    "\n",
    "* `Snakemake` [homepage](https://snakemake.github.io/)\n",
    "* `Snakemake` [documentation](https://snakemake.readthedocs.io/)\n",
    "* `Snakemake` [tutorial](https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<sub> ¬© Anan Ibrahim, Carl-Eric Wegner 2023-09 </sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

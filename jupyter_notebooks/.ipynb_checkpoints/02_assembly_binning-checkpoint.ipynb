{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1868c788-2281-461d-b1e5-58e5e65764c9",
   "metadata": {},
   "source": [
    "# \"Molecular Microbial Ecology\" MBGW2.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e875cef-5e5e-4fef-af3c-63ee63a792a0",
   "metadata": {},
   "source": [
    "## A look into the theory behind (meta)genome assembly\n",
    "Metagenome datasets usually originate from the sequencing of environmental genomic DNA, which means that sequenced DNA fragments originate from thousands to millions of taxonomically diverse microbes. With reference to metagenome assembly this kind of sounds like a problem and yes it is a problem. High-throughput sequencing platforms generate between 100Ks and 1Bs of sequence reads. How do we stitch them together?\n",
    "\n",
    "This question was actually answered quite a while ago, namely in the city of Königsberg, by the mathematician Leonhard Euler, who founded graph theory ⁠. The Königsberg problem refers to the seven bridges of Königsberg. In the 18<sup>th</sup> century the residents of Königsberg wondered whether every part of the city could be visited by walking each bridge only once and returning to ones starting point. Eulers idea was as simple as brilliant. He imagined every landmass of the city as a node, and every bridge as an edge, resulting in a network of nodes connected by edges. The original question was thus simplified to finding a path in the network, which visits every edge once.\n",
    "\n",
    "<img src=\"img/konigsberg.png\" alt=\"The bridges of Königsberg problem\" width=\"750\"/>\n",
    "\n",
    "<font size=\"2\"> The bridges of Königsberg problem? [_Compeau et al., 2011_](https://www.nature.com/articles/nbt.2023) </font>\n",
    "\n",
    "This idea was taken further by Nicolas de Bruijn, who invented de Bruijn graphs. A de Bruijn graph is a cyclic sequence of letters taken from a given alphabet for which every possible word of a certain length (k) appears as a string of consecutive characters in the cyclic sequence exactly once. Transferring this idea to metagenome sequencing means the following: we split our sequenced metagenome reads into k-mers with a length k and plot them in a graph where nodes represent (k-1)-mers and edges represent our k-mers. From a computational perspective this is still demanding, but it is a solvable problem. Most currently used (meta)genome assemblers are based on de Bruijn graphs, and while first assemblers had high computational requirements, primarily RAM for storing intermediate de Bruijn graphs, recent assemblers are able to run on almost standard, everyday hardware.\n",
    "\n",
    "<img src=\"img/seq.png\" alt=\"K-mers and (K-1)-mers\" width=\"500\"/>\n",
    "<img src=\"img/debruijn.png\" alt=\"De Bruijn graphs\" width=\"750\"/>\n",
    "<font size=\"2\"> Example, de Bruijn graph-based assembly. </font>\n",
    "\n",
    "## Taxonomic assignment of metagenomic sequence reads\n",
    "Before we assembly our sequence data we want to get a first glimpse into the taxonomic affiliation of our sequence reads. For this purpose many tools are available. A lot of them make use of k-mer or substring matching. For our datasets we will use `kaiju` with its available [webserver](http://kaiju.binf.ku.dk/server).\n",
    "\n",
    "<img src=\"img/kraken.png\" alt=\"Kraken\" width=\"750\"/>\n",
    "\n",
    "<font size=\"2\"> The k-mer matching based algorithm underlying Kraken, [_Wood and Salzberg, 2014_](https://genomebiology.biomedcentral.com/articles/10.1186/gb-2014-15-3-r46) </font>\n",
    "\n",
    "<img src=\"img/kaiju.png\" alt=\"Kaiju\" width=\"750\"/>\n",
    "\n",
    "<font size=\"2\"> The substring matching approach of Kaiju, [_Menzel et al., 2016_](https://www.nature.com/articles/ncomms11257) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b4d61-87a0-4309-8acc-dd261f8c07d0",
   "metadata": {},
   "source": [
    "## Session 02 | Initial taxonomic assignment and metagenome assembly\n",
    "\n",
    "### Quick taxonomic analysis with kaiju\n",
    "\n",
    "Let's do this quick and dirty taxonomic analysis.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>QUESTION/TASK:</b> \n",
    "<ul>\n",
    "  <li>Download forward and reverse reads and upload them to the Kaiju webserver. Execute the analysis with default settings, the webserver will run for approx. 30 min.</li>\n",
    "  <li>What is your impression of the taxonomic diversity within our dataset?</li>\n",
    "  <li>How big is the proportion of taxonomically assigned sequences?</li>\n",
    "  <li>What do you think are typical assignment rates when you deal with metagenome datasets?</li>  \n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<img src=\"img/kaiju_mask.png\" alt=\"Kaiju UI\" width=\"500\"/>\n",
    "\n",
    "<font size=\"2\"> _Kaiju's_ user interface / job submission form. </font>\n",
    "\n",
    "### A quick word about conda\n",
    "\n",
    "Throughout the course we use many different software tools. A lot of these tools have conflicting dependencies (tool X relies on package Z, tool Y too, but tool Y needs version 0.2 of Z, while tool X needs version 0.1). In order to have them available anyway, we use `virtual environments` (and `container`) a lot in bioinformatics.\n",
    "\n",
    "`conda` is a package manager and tool to set up and manage `virtual environments`. `Virtual environments` can be best imagined as encapsulations that are to a certain extent isolated from the respective computer system/operating system. \n",
    "\n",
    "By default, every user on our servers can make use of global `conda`.\n",
    "\n",
    "One can check available `conda` environments as follows:\n",
    "\n",
    "`conda info --envs`\n",
    "\n",
    "Environments are activated and deactivated using the following commands:\n",
    "\n",
    "`conda activate <name_of_environment>`\n",
    "\n",
    "`conda deactivate`\n",
    "\n",
    "### Metagenome co-assembly with MEGAHIT and METASPADES\n",
    "\n",
    "Having some first taxonomic information available, we proceed to metagenome assembly. We will use two different assemblers, [`MEGAHIT`](https://github.com/voutcn/megahit) and [`SPADES`](https://cab.spbu.ru/software/spades/). `MEGAHIT` is a very fast, memory-efficient short-read assembler, while `SPADES` is commonly considered the \"best\" short-read assembler available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90c6d373-7511-43cc-98c3-4926fa2e65e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">NODE_1_length_925458_cov_9.567712\n",
      "ATTGAATAAAAACTAATATTTCTGAAGATCAAAAGGTGAGCTTAGAAATGAAAATGAATT\n",
      "TTATTTATTCCCTTTTAACGATAGTTCCTAACCAGAAGGCTTTTGACTGGAATTGAGAGC\n",
      "TCGTCGATGGCCAATTTTCAGTAGTGAAATTATTTAGCGTGAAGGAAAAATCTTGAGCTG\n",
      "TAAACCAGCTCAAATCGGGAATATGTTTAAATGAATTTGTATTTTCAATTTTAGATGTAC\n",
      "CCCTACCATTGGACACGCTTGAATCGATTTCATTGCAACAATGGGGGCTTTTAACAACTT\n",
      "CTTTATCTTCGAAATCTTCCGTTTCATGATCCTGTACATCTATAGAAGAGGTGTGTGCAT\n",
      "TAGCAGTATGAACAAAACTATGGGATTTAAAGCAAGTATTACCTGCTAGGGAAAAACCAA\n",
      "CAATGAGAACGAAAATTATATGAAGAAGTTTTTTCACAATTTTTATAGTACTTGGCCGGT\n",
      "ACCTTAATGGGAAAGCTGTAATTTGTCAAAATACTATTTTAGTGCCCCATCATTGAGTGG\n"
     ]
    }
   ],
   "source": [
    "### We switch to our workshop folder and activate a needed conda environment\n",
    "# cd ~/data/MBGW223\n",
    "# conda activate assemblers\n",
    "### We first use MEGAHIT to co-assemble our two datasets ...\n",
    "# megahit -1 ./00_READS/dataset_A_1.fastq.gz,./00_READS/dataset_B_1.fastq.gz  -2 ./00_READS/dataset_A_2.fastq.gz,./00_READS/dataset_B_2.fastq.gz -m 0.05 -t 8 -o ./02_ASSEMBLY_BINNING/assembly_megahit\n",
    "### ... and then SPADES in metagenome mode\n",
    "# cat ./00_READS/*1.fastq.gz > ./00_READS/merged_1.fastq.gz\n",
    "# cat ./00_READS/*2.fastq.gz > ./00_READS/merged_2.fastq.gz\n",
    "# spades.py -t 8 --only-assembler -o ./02_ASSEMBLY_BINNING/assembly_spades --meta -1 ./00_READS/merged_1.fastq.gz -2 ./00_READS/merged_2.fastq.gz \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9de9272-098a-4964-bc9b-657bbf370224",
   "metadata": {},
   "source": [
    "A quick word about the used parameters:\n",
    "\n",
    "`--presets`: MEGAHIT comes with different k-mer presets dependent on the complexity of the metagenome\n",
    "\n",
    "`-t`: We specify eight threads for the assembly, time is money, but we also do not want to block all our server capacity\n",
    "\n",
    "`-1 / -2`: Forward and reverse reads to assemble\n",
    "\n",
    "`--meta`: Similar to _MEGAHIT_, _SPADES_ comes with presets, --meta (surprise) is the preset for metagenomes\n",
    "\n",
    "`-o`: output folders\n",
    "\n",
    "`--only-assembler`: SPADES usually starts the assembly with a very thorough QC based on provided .fastq files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a1972c-2721-4344-9a8f-3cbac6a9fcfe",
   "metadata": {},
   "source": [
    "Which assembler did a better job, how can we assess this, what are parameters/variables to look at? We use [`QUAST`](https://github.com/ablab/quast) to check out our assemblies.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>QUESTION/TASK:</b> \n",
    "<ul>\n",
    "  <li>Use Use QUAST to get some basic statistics about the assembled sets of contigs.</li>\n",
    "  <li>What parameters are calculated, how can they help you judge the performance of the assemblers?</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b385a-491a-4395-945b-a45480fa66e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We switch the conda environment and use quast.py to check the assemblies\n",
    "cd ~/data/MBGW223\n",
    "conda deactivate\n",
    "conda activate metawrap\n",
    "### We check first the MEGAHIT assembly and then the SPADES assembly\n",
    "quast.py -o ./02_ASSEMBLY_BINNING/assembly_megahit/quast ./02_ASSEMBLY_BINNING/assembly_megahit/final.contigs.fa\n",
    "quast.py -o ./02_ASSEMBLY_BINNING/assembly_spades/quast ./02_ASSEMBLY_BINNING/assembly_spades/contigs.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a92a54d-f817-490f-b76f-947ae9c79bc5",
   "metadata": {},
   "source": [
    "Used parameters:\n",
    "\n",
    "`-o`: we define an output folder, where `QUAST` should store its reports.\n",
    "\n",
    "Once the assembly is done, one important question is - \"With how many genomes are we dealing with in our assembly?\". In order to answer this question we make use of [`anvio`](http://merenlab.org/software/anvio/). _anvio_ is \"an open-source, community-driven analysis and visualization platform for microbial ‘omics. It brings together many aspects of today’s cutting-edge strategies including genomics, metagenomics, metatranscriptomics, pangenomics, metapangenomics, phylogenomics, and microbial population genetics in an integrated and easy-to-use fashion through extensive interactive visualization capabilities\". Few years ago we had the chance to host a workshop together with the main developer of anvio , which was a great experience. `anvio` is one lighthouse example for a community-effort to make cutting edge methods available to a broad group of (non-nerdy) users.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>QUESTION/TASK:</b> \n",
    "How many genomes can we expect from the assembly?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21191cae-c7da-4547-b1fe-ce187abd0ce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(/home/lu87neb/data/programs/conda/jupyterlab) \n",
      ">k141_8 flag=0 multi=117.0295 len=446\n",
      "CCAGTCACCGTCGAATAGAACGGCACCGACGACGACCGAGGACTGATCCCGGCAAGCTCCCTCGCCAACTCGCCCTCGATCGCCTCCACATGAGCGCAATGCGAGGCGTAATCCACCGGCACACGCCGCGCCCGGACCCCCTCACCCTCACACACGGCCAGCAACTCCTCCAACGCATCCGCATCACCGGAAACCACCACCGCCAACGGCCCGTTCACCGCCGCCACCGACAACCGCTCACCCCACGCCCCCAGCCACTCCCGCACCTCCCCCACCGGCAACGACACCGACACCATCCCCCCACGCCCCGACAACGCCCGCAACGCCCTACTCCGCAACGCCACCACCCGCGCCGCATCCTCCAACGACAACCCACCCGCCACACACGCCGCCGCAATCTCACCCTGCGAATGACCCACCACCGCAGCAGGCTCCACCCCATACGA\n",
      ">k141_9 flag=1 multi=36.0997 len=502\n",
      "AGGTAATCTGACCATAGCCATGGCTAAAACTACGTAGTTCCAACATTGTATCACATCCTAGCCATAGGTGGCTGGCACCACCTGTGGTTATGGTGCCAAAAAAAACTTTATTTTACAAAGAAATGATGAGTGAAACAGTTATGCGAATATAAAATAGCCAGCGAGGGTTCACTTCATCCCCGACCTAAAGGTCAGGGTATTCGTGACCCTCTGCGCTCCCATAGTAATAAAGTTTAAAAGAAGAGCATACAAAGGCAAGCAAAAACAGGACGAGATGATTGTACGTCTTGTTGCAGTCTATAATGACGAGGATGAAAAGTACCATATTTATATCACAAATATTCAGAAAGATATTTTGAACGCACAAGACATTGCAAACCTATATGGAGCAAGATGGGACATAGAACTGTTGTTTAAGGAATTGAAAAGCAAATATGCGCTGGACGTTCTTGAAACAAAGAATGTGCAGGTAATTGAAGCTCTAATCTGGACAGCAATATTG\n",
      ">k141_10 flag=0 multi=132.1200 len=491\n",
      "CGATACCAGTACCCGGCATCCAGCCCCGCCGTATCCAGCACCCCACCAGTCACCGTCGAATAGAACGGCACCGACGACGACCGAGGACTGATCCCGGCAAGCTCCCTCGCCAACTCGCCCTCGATCGCCTCCACATGAGCGCAATGCGAGGCGTAATCCACCGGAACACGCCGCGCCCGGACCCCCTCGCCCCCGCATACGGCCAGCAACTCCTCCAACGCATCCGCGTCACCGGAAACCACCACCGCCAACGGCCCGTTCACCGCCGCCACCGACAACCGCTCACCCCACCGGCCCAGCCGCTCCCGCACCGAGTCCACCGGCAACGACACCGACACCATCCCGCCCATCCCCGACAACGCCCGCAACGCCCTACTCCGCAACGCCACCACCCGCGCCGCATCCTCCAACGACAACCCACCCGCCACACACGCCGCCGCAATCTCACCCTGCGAATGACCCACCACCGCAGCAGGCTCCACCCCATACGA\n",
      ">k141_11 flag=0 multi=59.0000 len=430\n",
      "CCGATGGGGTGAATGTGTGCGTCCGGTCCGGGGAACACAAGGGTGATCTGGTCGGTGTCCGACCACCGCACGTCATAGGGAGGTGTCCCGTCGTCATGGTGGAGTCCGACGATCTCACCGTCCCGTTTGGTGGCACCGCTGGTGGGGCTTTCGACAATCAGCTGGTCGCCGACATGGGCACGCATCGACATCCCGCCTCTCCTGCCTGACGTCGTCCACTGTGACACCGCCGGTGAGCGGTGTCCTGGGGGCGGAACGCCCTCGGCCGAGGGGCCGGATGGCCCCGTGGTGGGCCGAGTGGCCGGGAGAGGGAGCCATGAGGCTCATCCGGCGGCGCGGGCGAGCTGGCAGGCTCGGTGGCGGAGCCGGGCTCGACGAGGGAGTCGGGCTCCGCGGCGGAAACACCGGCCGGCCCACCGCGGGTGTGCGA\n",
      ">k141_14 flag=0 multi=69.0891 len=758\n",
      "AAAGTATCTCCCAAACGAATTCTTATCCTCAACTTTATTTTGCATTTCTGTCAACACCAGTAGTTGATATGCTATGAAACTCAATAGAGAGTAGAGTTTTCTACTCTGATTTCTCACTCTTCTGATATCGAACTTTACTGTACCTTTAATATGTCCATGTATCTTTTCACATTCAGCTCTCTTTTTATACTGATCATCAAAAGTCTCATCTCTGATATTTTGGTTTCTTAGGTACATTCCTACCTGTTCTTTCCTTCCAATTTCATATAGAAATCTGAGTTTGTTTTCCATTGGTGCATGAATATCTCCACCGAGTTTCCACTTTTTATTCACCCAGTGATCGATTCGTTCCTCTTCACCTTCTTGATTGATTACTGCATTTGAAGCGTAGGAAATAATCGGTTTTGCGTTCAGATTATACCAAATATCAGAATGATTGAGGAATGAATCATAACCTCCGTCAGCAGAATAAAATTCCAGATTAGCGTTCATGTTCTTTAGAGCCTCAATATGGTCGATAAGTTCTGGAGAGTCACCAGAAAGTCCTTTTGTATGAGTCATGAAAATTGGATAAGTTCCAACCATTGTAATATGTGCCTTATCCATTTTGCATTCATAATGAGGATTATAATCAGCATGTTTGTCGTATCTTGAAGCTTCAAGTGGAGTGGAATCAATTTTTGCTTCCTTTTCCTGAGAAAGTTTGAGAATTTTCTCACCTATAAGCATCATTATCTCATTGACTCCTTTTTCTCCAA\n",
      "head: cannot open './02_ASSEMBLY_BINNINGY/assembly_spades/contigs.fasta' for reading: No such file or directory\n",
      "\u001b[0;36mInput\u001b[0m ........................................: \u001b[0;33m./02_ASSEMBLY_BINNING/assembly_megahit/final.contigs.fa\u001b[0m\n",
      "\u001b[0;36mOutput\u001b[0m .......................................: \u001b[0;33m./02_ASSEMBLY_BINNING/assembly_megahit/contigs_renamed.fa\u001b[0m\n",
      "\u001b[0;36mMinimum length\u001b[0m ...............................: \u001b[0;33m0\u001b[0m\n",
      "\u001b[0;36mMax % gaps allowed\u001b[0m ...........................: \u001b[0;33m100.00%\u001b[0m\n",
      "\u001b[0;36mTotal num contigs\u001b[0m ............................: \u001b[0;33m1,619\u001b[0m\n",
      "\u001b[0;36mTotal num nucleotides\u001b[0m ........................: \u001b[0;33m44,253,132\u001b[0m\n",
      "\u001b[0;36mContigs removed\u001b[0m ..............................: \u001b[0;32m0 (0.00% of all)\u001b[0m\n",
      "\u001b[0;36mNucleotides removed\u001b[0m ..........................: \u001b[0;32m0 (0.00% of all)\u001b[0m\n",
      "\u001b[0;36mNucleotides modified\u001b[0m .........................: \u001b[0;32m0 (0.00% of all)\u001b[0m\n",
      "\u001b[0;36mDeflines simplified\u001b[0m ..........................: \u001b[0;32mTrue\u001b[0m\n",
      "\u001b[0;36mInput\u001b[0m ........................................: \u001b[0;33m./02_ASSEMBLY_BINNING/assembly_spades/contigs.fasta\u001b[0m\n",
      "\u001b[0;36mOutput\u001b[0m .......................................: \u001b[0;33m./02_ASSEMBLY_BINNING/assembly_spades/contigs_renamed.fa\u001b[0m\n",
      "\u001b[0;36mMinimum length\u001b[0m ...............................: \u001b[0;33m0\u001b[0m\n",
      "\u001b[0;36mMax % gaps allowed\u001b[0m ...........................: \u001b[0;33m100.00%\u001b[0m\n",
      "\u001b[0;36mTotal num contigs\u001b[0m ............................: \u001b[0;33m1,267\u001b[0m\n",
      "\u001b[0;36mTotal num nucleotides\u001b[0m ........................: \u001b[0;33m44,226,233\u001b[0m\n",
      "\u001b[0;36mContigs removed\u001b[0m ..............................: \u001b[0;32m0 (0.00% of all)\u001b[0m\n",
      "\u001b[0;36mNucleotides removed\u001b[0m ..........................: \u001b[0;32m0 (0.00% of all)\u001b[0m\n",
      "\u001b[0;36mNucleotides modified\u001b[0m .........................: \u001b[0;32m0 (0.00% of all)\u001b[0m\n",
      "\u001b[0;36mDeflines simplified\u001b[0m ..........................: \u001b[0;32mTrue\u001b[0m\n",
      "\u001b[0;36mInput FASTA file\u001b[0m .............................: \u001b[0;33m/data/lu87neb/MBGW223/02_ASSEMBLY_BINNING/assembly_megahit/contigs_renamed.fa\u001b[0m\n",
      "\u001b[0;36mName\u001b[0m .........................................: \u001b[0;32mmock_metagenome_megahit\u001b[0m\n",
      "\u001b[0;36mDescription\u001b[0m ..................................: \u001b[0;32mNo description is given\u001b[0m\n",
      "\u001b[0;36mNum threads for gene calling\u001b[0m .................: \u001b[0;33m6\u001b[0m         [0m\n",
      "\u001b[0;32m\n",
      "Finding ORFs in contigs\n",
      "===============================================\n",
      "\u001b[0m\u001b[0;36mGenes\u001b[0m ........................................: \u001b[0;33m/tmp/tmp5d4bzq7i/contigs.genes\u001b[0m\n",
      "\u001b[0;36mAmino acid sequences\u001b[0m .........................: \u001b[0;33m/tmp/tmp5d4bzq7i/contigs.amino_acid_sequences\u001b[0m\n",
      "\u001b[0;36mLog file\u001b[0m .....................................: \u001b[0;33m/tmp/tmp5d4bzq7i/00_log.txt\u001b[0m\n",
      "\u001b[0;32m\n",
      "CITATION\n",
      "===============================================\n",
      "\u001b[0m\u001b[0;32mAnvi'o will use 'prodigal' by Hyatt et al (doi:10.1186/1471-2105-11-119) to\n",
      "identify open reading frames in your data. When you publish your findings,\n",
      "please do not forget to properly credit their work.\n",
      "\n",
      "\u001b[0;36mResult\u001b[0m .......................................: \u001b[0;33mProdigal (v2.6.3) has identified\n",
      "                                                40094 genes.\u001b[0m\n",
      "\n",
      "\u001b[0;36m                                                                         [0m\n",
      "CONTIGS DB CREATE REPORT\n",
      "===============================================\n",
      "\u001b[0m\u001b[0;36mSplit Length\u001b[0m .................................: \u001b[0;33m20,000\u001b[0m\n",
      "\u001b[0;36mK-mer size\u001b[0m ...................................: \u001b[0;33m4\u001b[0m\n",
      "\u001b[0;36mSkip gene calling?\u001b[0m ...........................: \u001b[0;33mFalse\u001b[0m\n",
      "\u001b[0;36mExternal gene calls provided?\u001b[0m ................: \u001b[0;32mFalse\u001b[0m\n",
      "\u001b[0;36mIgnoring internal stop codons?\u001b[0m ...............: \u001b[0;33mFalse\u001b[0m\n",
      "\u001b[0;36mSplitting pays attention to gene calls?\u001b[0m ......: \u001b[0;33mTrue\u001b[0m\n",
      "\u001b[0;36mContigs with at least one gene call\u001b[0m ..........: \u001b[0;33m1578 of 1619 (97.5%)\u001b[0mm\u001b[48;5;239m\u001b[38;5;15m\u001b[48;5;244m\u001b[38;5;14m ETA: 0s\u001b[0m\u001b[48;5;6m\u001b[38;5;0m                                                                                \n",
      "\u001b[0;36mContigs database\u001b[0m .............................: \u001b[0;33mA new database,\n",
      "                                                ./02_ASSEMBLY_BINNING/mock_metagenome_megahit-CONTIGS.db,\n",
      "                                                has been created.\u001b[0m\n",
      "\u001b[0;36mNumber of contigs\u001b[0m ............................: \u001b[0;33m1,619\u001b[0m\n",
      "\u001b[0;36mNumber of splits\u001b[0m .............................: \u001b[0;33m2,956\u001b[0m\n",
      "\u001b[0;36mTotal number of nucleotides\u001b[0m ..................: \u001b[0;33m44,253,132\u001b[0m\n",
      "\u001b[0;36mGene calling step skipped\u001b[0m ....................: \u001b[0;33mFalse\u001b[0m\n",
      "\u001b[0;36mSplits broke genes (non-mindful mode)\u001b[0m ........: \u001b[0;33mFalse\u001b[0m\n",
      "\u001b[0;36mDesired split length (what the user wanted)\u001b[0m ..: \u001b[0;33m20,000\u001b[0m\n",
      "\u001b[0;36mAverage split length (what anvi'o gave back)\u001b[0m .: \u001b[0;33m21,693\u001b[0m\n",
      "\n",
      "\u001b[0;32m✓ anvi-gen-contigs-database took 0:02:16.386659\n",
      "\u001b[0m\n",
      "\u001b[0;36mInput FASTA file\u001b[0m .............................: \u001b[0;33m/data/lu87neb/MBGW223/02_ASSEMBLY_BINNING/assembly_spades/contigs_renamed.fa\u001b[0m\n",
      "\u001b[0;36mName\u001b[0m .........................................: \u001b[0;32mmock_metagenome_spaded\u001b[0m\n",
      "\u001b[0;36mDescription\u001b[0m ..................................: \u001b[0;32mNo description is given\u001b[0m\n",
      "\u001b[0;36mNum threads for gene calling\u001b[0m .................: \u001b[0;33m6\u001b[0m         [0m\n",
      "\u001b[0;32m\n",
      "Finding ORFs in contigs\n",
      "===============================================\n",
      "\u001b[0m\u001b[0;36mGenes\u001b[0m ........................................: \u001b[0;33m/tmp/tmpf2rtmk9g/contigs.genes\u001b[0m\n",
      "\u001b[0;36mAmino acid sequences\u001b[0m .........................: \u001b[0;33m/tmp/tmpf2rtmk9g/contigs.amino_acid_sequences\u001b[0m\n",
      "\u001b[0;36mLog file\u001b[0m .....................................: \u001b[0;33m/tmp/tmpf2rtmk9g/00_log.txt\u001b[0m\n",
      "\u001b[0;32m\n",
      "CITATION\n",
      "===============================================\n",
      "\u001b[0m\u001b[0;32mAnvi'o will use 'prodigal' by Hyatt et al (doi:10.1186/1471-2105-11-119) to\n",
      "identify open reading frames in your data. When you publish your findings,\n",
      "please do not forget to properly credit their work.\n",
      "\n",
      "\u001b[0;36mResult\u001b[0m .......................................: \u001b[0;33mProdigal (v2.6.3) has identified\n",
      "                                                39558 genes.\u001b[0m\n",
      "\n",
      "\u001b[0;36m                                                                         [0m\n",
      "CONTIGS DB CREATE REPORT\n",
      "===============================================\n",
      "\u001b[0m\u001b[0;36mSplit Length\u001b[0m .................................: \u001b[0;33m20,000\u001b[0m\n",
      "\u001b[0;36mK-mer size\u001b[0m ...................................: \u001b[0;33m4\u001b[0m\n",
      "\u001b[0;36mSkip gene calling?\u001b[0m ...........................: \u001b[0;33mFalse\u001b[0m\n",
      "\u001b[0;36mExternal gene calls provided?\u001b[0m ................: \u001b[0;32mFalse\u001b[0m\n",
      "\u001b[0;36mIgnoring internal stop codons?\u001b[0m ...............: \u001b[0;33mFalse\u001b[0m\n",
      "\u001b[0;36mSplitting pays attention to gene calls?\u001b[0m ......: \u001b[0;33mTrue\u001b[0m\n",
      "[23 Aug 23 12:56:52 The South Loop] Contig \"1010\" has 1 \u001b[48;5;209m\u001b[38;5;0m\u001b[48;5;239m\u001b[38;5;15mgenes, k (...)\u001b[48;5;244m\u001b[38;5;14m ETA: 37s\u001b[0m\u001b[48;5;6m\u001b[38;5;0m\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;36mContigs DB\u001b[0m ...................................: \u001b[0;33m./02_ASSEMBLY_BINNING/mock_metagenome_megahit-CONTIGS.db\u001b[0m\n",
      "\u001b[0;36mHMM sources\u001b[0m ..................................: \u001b[0;33mBacteria_71, Archaea_76,\n",
      "                                                Ribosomal_RNA_16S\u001b[0m\n",
      "\u001b[0;36mAlphabet/context target found\u001b[0m ................: \u001b[0;33mRNA:CONTIG\u001b[0m\n",
      "\u001b[0;36mAlphabet/context target found\u001b[0m ................: \u001b[0;33mAA:GENE\u001b[0m   [0m\n",
      "\u001b[0;32m                                                                         [0m                                                                                                                                                                                                                                                                                                                                \n",
      "HMM Profiling for Bacteria_71\n",
      "===============================================\n",
      "\u001b[0m\u001b[0;36mReference\u001b[0m ....................................: \u001b[0;33mLee modified,\n",
      "                                                https://doi.org/10.1093/bioinformatics/btz188\u001b[0m\n",
      "\u001b[0;36mKind\u001b[0m .........................................: \u001b[0;33msinglecopy\u001b[0m\n",
      "\u001b[0;36mAlphabet\u001b[0m .....................................: \u001b[0;33mAA\u001b[0m\n",
      "\u001b[0;36mContext\u001b[0m ......................................: \u001b[0;33mGENE\u001b[0m\n",
      "\u001b[0;36mDomain\u001b[0m .......................................: \u001b[0;33mbacteria\u001b[0m\n",
      "\u001b[0;36mHMM model path\u001b[0m ...............................: \u001b[0;33m/tmp/tmpq9yfsy4p/Bacteria_71.hmm\u001b[0m\n",
      "\u001b[0;36mNumber of genes in HMM model\u001b[0m .................: \u001b[0;33m71\u001b[0m\n",
      "\u001b[0;36mNoise cutoff term(s)\u001b[0m .........................: \u001b[0;33m--cut_ga\u001b[0m\n",
      "\u001b[0;36mNumber of CPUs will be used for search\u001b[0m .......: \u001b[0;33m6\u001b[0m\n",
      "\u001b[0;36mHMMer program used for search\u001b[0m ................: \u001b[0;33mhmmscan\u001b[0m\n",
      "\u001b[0;36mTemporary work dir\u001b[0m ...........................: \u001b[0;33m/tmp/tmptc0e8x5t\u001b[0m\n",
      "\u001b[0;36mLog file for thread 0\u001b[0m ........................: \u001b[0;33m/tmp/tmptc0e8x5t/AA_gene_sequences.fa.0_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 1\u001b[0m ........................: \u001b[0;33m/tmp/tmptc0e8x5t/AA_gene_sequences.fa.1_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 2\u001b[0m ........................: \u001b[0;33m/tmp/tmptc0e8x5t/AA_gene_sequences.fa.2_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 3\u001b[0m ........................: \u001b[0;33m/tmp/tmptc0e8x5t/AA_gene_sequences.fa.3_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 4\u001b[0m ........................: \u001b[0;33m/tmp/tmptc0e8x5t/AA_gene_sequences.fa.4_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 5\u001b[0m ........................: \u001b[0;33m/tmp/tmptc0e8x5t/AA_gene_sequences.fa.5_log\u001b[0m\n",
      "\u001b[0;36mDone 🎊                                                                  [0m\n",
      "\u001b[0m\n",
      "\u001b[0;36mNumber of raw hits in table file\u001b[0m .............: \u001b[0;33m603\u001b[0m       \n",
      "\u001b[0;36mNumber of weak hits removed by HMMER parser\u001b[0m ..: \u001b[0;33m0\u001b[0m\n",
      "\u001b[0;36mNumber of hits in annotation dict \u001b[0m ...........: \u001b[0;33m603\u001b[0m\n",
      "\u001b[0;32m\n",
      "HMM Profiling for Archaea_76\n",
      "===============================================\n",
      "\u001b[0m\u001b[0;36mReference\u001b[0m ....................................: \u001b[0;33mLee,\n",
      "                                                https://doi.org/10.1093/bioinformatics/btz188\u001b[0m\n",
      "\u001b[0;36mKind\u001b[0m .........................................: \u001b[0;33msinglecopy\u001b[0m\n",
      "\u001b[0;36mAlphabet\u001b[0m .....................................: \u001b[0;33mAA\u001b[0m\n",
      "\u001b[0;36mContext\u001b[0m ......................................: \u001b[0;33mGENE\u001b[0m\n",
      "\u001b[0;36mDomain\u001b[0m .......................................: \u001b[0;33marchaea\u001b[0m\n",
      "\u001b[0;36mHMM model path\u001b[0m ...............................: \u001b[0;33m/tmp/tmpq9yfsy4p/Archaea_76.hmm\u001b[0m\n",
      "\u001b[0;36mNumber of genes in HMM model\u001b[0m .................: \u001b[0;33m76\u001b[0m\n",
      "\u001b[0;36mNoise cutoff term(s)\u001b[0m .........................: \u001b[0;33m--cut_ga\u001b[0m\n",
      "\u001b[0;36mNumber of CPUs will be used for search\u001b[0m .......: \u001b[0;33m6\u001b[0m\n",
      "\u001b[0;36mHMMer program used for search\u001b[0m ................: \u001b[0;33mhmmscan\u001b[0m\n",
      "\u001b[0;36mTemporary work dir\u001b[0m ...........................: \u001b[0;33m/tmp/tmptc0e8x5t\u001b[0m\n",
      "\u001b[0;36mLog file for thread 0\u001b[0m ........................: \u001b[0;33m/tmp/tmptc0e8x5t/AA_gene_sequences.fa.0_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 1\u001b[0m ........................: \u001b[0;33m/tmp/tmptc0e8x5t/AA_gene_sequences.fa.1_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 2\u001b[0m ........................: \u001b[0;33m/tmp/tmptc0e8x5t/AA_gene_sequences.fa.2_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 3\u001b[0m ........................: \u001b[0;33m/tmp/tmptc0e8x5t/AA_gene_sequences.fa.3_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 4\u001b[0m ........................: \u001b[0;33m/tmp/tmptc0e8x5t/AA_gene_sequences.fa.4_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 5\u001b[0m ........................: \u001b[0;33m/tmp/tmptc0e8x5t/AA_gene_sequences.fa.5_log\u001b[0m\n",
      "\u001b[0;36mDone 🎊                                                                  [0m\n",
      "\u001b[0m\n",
      "\u001b[0;36mNumber of raw hits in table file\u001b[0m .............: \u001b[0;33m459\u001b[0m       \n",
      "\u001b[0;36mNumber of weak hits removed by HMMER parser\u001b[0m ..: \u001b[0;33m0\u001b[0m\n",
      "\u001b[0;36mNumber of hits in annotation dict \u001b[0m ...........: \u001b[0;33m459\u001b[0m\n",
      "\u001b[0;32m                                                                         [0m\n",
      "HMM Profiling for Ribosomal_RNA_16S\n",
      "===============================================\n",
      "\u001b[0m\u001b[0;36mReference\u001b[0m ....................................: \u001b[0;33mSeeman T,\n",
      "                                                https://github.com/tseemann/barrnap\u001b[0m\n",
      "\u001b[0;36mKind\u001b[0m .........................................: \u001b[0;33mRibosomal_RNA_16S\u001b[0m\n",
      "\u001b[0;36mAlphabet\u001b[0m .....................................: \u001b[0;33mRNA\u001b[0m\n",
      "\u001b[0;36mContext\u001b[0m ......................................: \u001b[0;33mCONTIG\u001b[0m\n",
      "\u001b[0;36mDomain\u001b[0m .......................................: \u001b[0;33mN/A\u001b[0m\n",
      "\u001b[0;36mHMM model path\u001b[0m ...............................: \u001b[0;33m/tmp/tmpq9yfsy4p/Ribosomal_RNA_16S.hmm\u001b[0m\n",
      "\u001b[0;36mNumber of genes in HMM model\u001b[0m .................: \u001b[0;33m3\u001b[0m\n",
      "\u001b[0;36mNoise cutoff term(s)\u001b[0m .........................: \u001b[0;33m--cut_ga\u001b[0m\n",
      "\u001b[0;36mNumber of CPUs will be used for search\u001b[0m .......: \u001b[0;33m6\u001b[0m\n",
      "\u001b[0;36mHMMer program used for search\u001b[0m ................: \u001b[0;33mnhmmscan\u001b[0m\n",
      "\u001b[0;36mTemporary work dir\u001b[0m ...........................: \u001b[0;33m/tmp/tmp_4uh8iim\u001b[0m\n",
      "\u001b[0;36mLog file for thread 0\u001b[0m ........................: \u001b[0;33m/tmp/tmp_4uh8iim/RNA_contig_sequences.fa.0_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 1\u001b[0m ........................: \u001b[0;33m/tmp/tmp_4uh8iim/RNA_contig_sequences.fa.1_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 2\u001b[0m ........................: \u001b[0;33m/tmp/tmp_4uh8iim/RNA_contig_sequences.fa.2_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 3\u001b[0m ........................: \u001b[0;33m/tmp/tmp_4uh8iim/RNA_contig_sequences.fa.3_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 4\u001b[0m ........................: \u001b[0;33m/tmp/tmp_4uh8iim/RNA_contig_sequences.fa.4_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 5\u001b[0m ........................: \u001b[0;33m/tmp/tmp_4uh8iim/RNA_contig_sequences.fa.5_log\u001b[0m\n",
      "\u001b[0;36mDone 🎊                                                                  [0m\n",
      "\u001b[0m\n",
      "\u001b[0;36mNumber of raw hits in table file\u001b[0m .............: \u001b[0;33m8\u001b[0m         \n",
      "\u001b[0;36mNumber of weak hits removed by HMMER parser\u001b[0m ..: \u001b[0;33m0\u001b[0m\n",
      "\u001b[0;36mNumber of hits in annotation dict \u001b[0m ...........: \u001b[0;33m8\u001b[0m\n",
      "\u001b[0;36mPruned\u001b[0m .......................................: \u001b[0;33m2 out of 8 hits were removed due\n",
      "                                                to redundancy\u001b[0m\n",
      "\u001b[0;36mGene calls added to db\u001b[0m .......................: \u001b[0;33m6 (from source[0m                                                                                                                                                                \n",
      "                                                \"Ribosomal_RNA_16S\")\u001b[0m\n",
      "                                                                                [0m\n",
      "\u001b[0;32m✓ anvi-run-hmms took 0:00:37.885501\n",
      "\u001b[0m\n",
      "\u001b[0;36mContigs DB\u001b[0m ...................................: \u001b[0;33m./02_ASSEMBLY_BINNING/mock_metagenome_spades-CONTIGS.db\u001b[0m\n",
      "\u001b[0;36mHMM sources\u001b[0m ..................................: \u001b[0;33mBacteria_71, Archaea_76,\n",
      "                                                Ribosomal_RNA_16S\u001b[0m\n",
      "\u001b[0;36mAlphabet/context target found\u001b[0m ................: \u001b[0;33mRNA:CONTIG\u001b[0m\n",
      "\u001b[0;36mAlphabet/context target found\u001b[0m ................: \u001b[0;33mAA:GENE\u001b[0m   [0m\n",
      "\u001b[0;32m                                                                         [0m                                                                                                                                                                                                                                                                                                                                \n",
      "HMM Profiling for Bacteria_71\n",
      "===============================================\n",
      "\u001b[0m\u001b[0;36mReference\u001b[0m ....................................: \u001b[0;33mLee modified,\n",
      "                                                https://doi.org/10.1093/bioinformatics/btz188\u001b[0m\n",
      "\u001b[0;36mKind\u001b[0m .........................................: \u001b[0;33msinglecopy\u001b[0m\n",
      "\u001b[0;36mAlphabet\u001b[0m .....................................: \u001b[0;33mAA\u001b[0m\n",
      "\u001b[0;36mContext\u001b[0m ......................................: \u001b[0;33mGENE\u001b[0m\n",
      "\u001b[0;36mDomain\u001b[0m .......................................: \u001b[0;33mbacteria\u001b[0m\n",
      "\u001b[0;36mHMM model path\u001b[0m ...............................: \u001b[0;33m/tmp/tmpkjxf2l_z/Bacteria_71.hmm\u001b[0m\n",
      "\u001b[0;36mNumber of genes in HMM model\u001b[0m .................: \u001b[0;33m71\u001b[0m\n",
      "\u001b[0;36mNoise cutoff term(s)\u001b[0m .........................: \u001b[0;33m--cut_ga\u001b[0m\n",
      "\u001b[0;36mNumber of CPUs will be used for search\u001b[0m .......: \u001b[0;33m6\u001b[0m\n",
      "\u001b[0;36mHMMer program used for search\u001b[0m ................: \u001b[0;33mhmmscan\u001b[0m\n",
      "\u001b[0;36mTemporary work dir\u001b[0m ...........................: \u001b[0;33m/tmp/tmpmdcylxv9\u001b[0m\n",
      "\u001b[0;36mLog file for thread 0\u001b[0m ........................: \u001b[0;33m/tmp/tmpmdcylxv9/AA_gene_sequences.fa.0_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 1\u001b[0m ........................: \u001b[0;33m/tmp/tmpmdcylxv9/AA_gene_sequences.fa.1_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 2\u001b[0m ........................: \u001b[0;33m/tmp/tmpmdcylxv9/AA_gene_sequences.fa.2_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 3\u001b[0m ........................: \u001b[0;33m/tmp/tmpmdcylxv9/AA_gene_sequences.fa.3_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 4\u001b[0m ........................: \u001b[0;33m/tmp/tmpmdcylxv9/AA_gene_sequences.fa.4_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 5\u001b[0m ........................: \u001b[0;33m/tmp/tmpmdcylxv9/AA_gene_sequences.fa.5_log\u001b[0m\n",
      "\u001b[0;36mDone 🎊                                                                  [0m\n",
      "\u001b[0m\n",
      "\u001b[0;36mNumber of raw hits in table file\u001b[0m .............: \u001b[0;33m604\u001b[0m       \n",
      "\u001b[0;36mNumber of weak hits removed by HMMER parser\u001b[0m ..: \u001b[0;33m0\u001b[0m\n",
      "\u001b[0;36mNumber of hits in annotation dict \u001b[0m ...........: \u001b[0;33m604\u001b[0m\n",
      "\u001b[0;32m\n",
      "HMM Profiling for Archaea_76\n",
      "===============================================\n",
      "\u001b[0m\u001b[0;36mReference\u001b[0m ....................................: \u001b[0;33mLee,\n",
      "                                                https://doi.org/10.1093/bioinformatics/btz188\u001b[0m\n",
      "\u001b[0;36mKind\u001b[0m .........................................: \u001b[0;33msinglecopy\u001b[0m\n",
      "\u001b[0;36mAlphabet\u001b[0m .....................................: \u001b[0;33mAA\u001b[0m\n",
      "\u001b[0;36mContext\u001b[0m ......................................: \u001b[0;33mGENE\u001b[0m\n",
      "\u001b[0;36mDomain\u001b[0m .......................................: \u001b[0;33marchaea\u001b[0m\n",
      "\u001b[0;36mHMM model path\u001b[0m ...............................: \u001b[0;33m/tmp/tmpkjxf2l_z/Archaea_76.hmm\u001b[0m\n",
      "\u001b[0;36mNumber of genes in HMM model\u001b[0m .................: \u001b[0;33m76\u001b[0m\n",
      "\u001b[0;36mNoise cutoff term(s)\u001b[0m .........................: \u001b[0;33m--cut_ga\u001b[0m\n",
      "\u001b[0;36mNumber of CPUs will be used for search\u001b[0m .......: \u001b[0;33m6\u001b[0m\n",
      "\u001b[0;36mHMMer program used for search\u001b[0m ................: \u001b[0;33mhmmscan\u001b[0m\n",
      "\u001b[0;36mTemporary work dir\u001b[0m ...........................: \u001b[0;33m/tmp/tmpmdcylxv9\u001b[0m\n",
      "\u001b[0;36mLog file for thread 0\u001b[0m ........................: \u001b[0;33m/tmp/tmpmdcylxv9/AA_gene_sequences.fa.0_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 1\u001b[0m ........................: \u001b[0;33m/tmp/tmpmdcylxv9/AA_gene_sequences.fa.1_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 2\u001b[0m ........................: \u001b[0;33m/tmp/tmpmdcylxv9/AA_gene_sequences.fa.2_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 3\u001b[0m ........................: \u001b[0;33m/tmp/tmpmdcylxv9/AA_gene_sequences.fa.3_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 4\u001b[0m ........................: \u001b[0;33m/tmp/tmpmdcylxv9/AA_gene_sequences.fa.4_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 5\u001b[0m ........................: \u001b[0;33m/tmp/tmpmdcylxv9/AA_gene_sequences.fa.5_log\u001b[0m\n",
      "\u001b[0;36mDone 🎊                                                                  [0m\n",
      "\u001b[0m\n",
      "\u001b[0;36mNumber of raw hits in table file\u001b[0m .............: \u001b[0;33m460\u001b[0m       \n",
      "\u001b[0;36mNumber of weak hits removed by HMMER parser\u001b[0m ..: \u001b[0;33m0\u001b[0m\n",
      "\u001b[0;36mNumber of hits in annotation dict \u001b[0m ...........: \u001b[0;33m460\u001b[0m\n",
      "\u001b[0;32m                                                                         [0m\n",
      "HMM Profiling for Ribosomal_RNA_16S\n",
      "===============================================\n",
      "\u001b[0m\u001b[0;36mReference\u001b[0m ....................................: \u001b[0;33mSeeman T,\n",
      "                                                https://github.com/tseemann/barrnap\u001b[0m\n",
      "\u001b[0;36mKind\u001b[0m .........................................: \u001b[0;33mRibosomal_RNA_16S\u001b[0m\n",
      "\u001b[0;36mAlphabet\u001b[0m .....................................: \u001b[0;33mRNA\u001b[0m\n",
      "\u001b[0;36mContext\u001b[0m ......................................: \u001b[0;33mCONTIG\u001b[0m\n",
      "\u001b[0;36mDomain\u001b[0m .......................................: \u001b[0;33mN/A\u001b[0m\n",
      "\u001b[0;36mHMM model path\u001b[0m ...............................: \u001b[0;33m/tmp/tmpkjxf2l_z/Ribosomal_RNA_16S.hmm\u001b[0m\n",
      "\u001b[0;36mNumber of genes in HMM model\u001b[0m .................: \u001b[0;33m3\u001b[0m\n",
      "\u001b[0;36mNoise cutoff term(s)\u001b[0m .........................: \u001b[0;33m--cut_ga\u001b[0m\n",
      "\u001b[0;36mNumber of CPUs will be used for search\u001b[0m .......: \u001b[0;33m6\u001b[0m\n",
      "\u001b[0;36mHMMer program used for search\u001b[0m ................: \u001b[0;33mnhmmscan\u001b[0m\n",
      "\u001b[0;36mTemporary work dir\u001b[0m ...........................: \u001b[0;33m/tmp/tmpifrqnpml\u001b[0m\n",
      "\u001b[0;36mLog file for thread 0\u001b[0m ........................: \u001b[0;33m/tmp/tmpifrqnpml/RNA_contig_sequences.fa.0_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 1\u001b[0m ........................: \u001b[0;33m/tmp/tmpifrqnpml/RNA_contig_sequences.fa.1_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 2\u001b[0m ........................: \u001b[0;33m/tmp/tmpifrqnpml/RNA_contig_sequences.fa.2_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 3\u001b[0m ........................: \u001b[0;33m/tmp/tmpifrqnpml/RNA_contig_sequences.fa.3_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 4\u001b[0m ........................: \u001b[0;33m/tmp/tmpifrqnpml/RNA_contig_sequences.fa.4_log\u001b[0m\n",
      "\u001b[0;36mLog file for thread 5\u001b[0m ........................: \u001b[0;33m/tmp/tmpifrqnpml/RNA_contig_sequences.fa.5_log\u001b[0m\n",
      "\u001b[0;36mDone 🎊                                                                  [0m\n",
      "\u001b[0m\n",
      "\u001b[0;36mNumber of raw hits in table file\u001b[0m .............: \u001b[0;33m8\u001b[0m         \n",
      "\u001b[0;36mNumber of weak hits removed by HMMER parser\u001b[0m ..: \u001b[0;33m0\u001b[0m\n",
      "\u001b[0;36mNumber of hits in annotation dict \u001b[0m ...........: \u001b[0;33m8\u001b[0m\n",
      "\u001b[0;36mPruned\u001b[0m .......................................: \u001b[0;33m2 out of 8 hits were removed due\n",
      "                                                to redundancy\u001b[0m\n",
      "\u001b[0;36mGene calls added to db\u001b[0m .......................: \u001b[0;33m6 (from source[0m                                                                                                                                                                \n",
      "                                                \"Ribosomal_RNA_16S\")\u001b[0m\n",
      "                                                                                [0m\n",
      "\u001b[0;32m✓ anvi-run-hmms took 0:00:54.914769\n",
      "\u001b[0m\n",
      "\u001b[0;36mOutput file\u001b[0m ..................................: \u001b[0;33m./02_ASSEMBLY_BINNING/stats_mock_metagenome_megahit.txt\u001b[0m                                                                                                                                                                                                      \n",
      "\u001b[0;36mOutput file\u001b[0m ..................................: \u001b[0;33m./02_ASSEMBLY_BINNING/stats_mock_metagenome_spades.txt\u001b[0m                                                                                                                                                                                                       \n"
     ]
    }
   ],
   "source": [
    "### We use anvio to estimate the number of genomes in our two assemblies\n",
    "### anvio expects that are contig names are formatted in consistent manner\n",
    "### How do our two .fasta files with assembled contigs look?!\n",
    "cd ~/data/MBGW223\n",
    "conda deactivate\n",
    "conda activate anvio7\n",
    "head ./02_ASSEMBLY_BINNING/assembly_megahit/final.contigs.fa\n",
    "head ./02_ASSEMBLY_BINNING/assembly_spades/contigs.fasta\n",
    "### In both cases, the header includes information about the contig assembly,\n",
    "### like contig length etc.\n",
    "### Let's reformat them\n",
    "anvi-script-reformat-fasta --simplify-names -o ./02_ASSEMBLY_BINNING/assembly_megahit/contigs_renamed.fa ./02_ASSEMBLY_BINNING/assembly_megahit/final.contigs.fa\n",
    "anvi-script-reformat-fasta --simplify-names -o ./02_ASSEMBLY_BINNING/assembly_spades/contigs_renamed.fa ./02_ASSEMBLY_BINNING/assembly_spades/contigs.fasta\n",
    "### We generate so called contig databases (explained below!), ...\n",
    "anvi-gen-contigs-database -f ./02_ASSEMBLY_BINNING/assembly_megahit/contigs_renamed.fa -n mock_metagenome_megahit -o ./02_ASSEMBLY_BINNING/mock_metagenome_megahit-CONTIGS.db -T 6\n",
    "anvi-gen-contigs-database -f ./02_ASSEMBLY_BINNING/assembly_spades/contigs_renamed.fa -n mock_metagenome_spaded -o ./02_ASSEMBLY_BINNING/mock_metagenome_spades-CONTIGS.db -T 6\n",
    "### ... identify certain genes, add this information (more about that in a bit) ...,\n",
    "anvi-run-hmms -c ./02_ASSEMBLY_BINNING/mock_metagenome_megahit-CONTIGS.db -I Bacteria_71,Archaea_76,Ribosomal_RNA_16S -T 6\n",
    "anvi-run-hmms -c ./02_ASSEMBLY_BINNING/mock_metagenome_spades-CONTIGS.db -I Bacteria_71,Archaea_76,Ribosomal_RNA_16S -T 6\n",
    "### ... and summarize them!\n",
    "anvi-display-contigs-stats --report-as-text -o ./02_ASSEMBLY_BINNING/stats_mock_metagenome_megahit.txt ./02_ASSEMBLY_BINNING/mock_metagenome_megahit-CONTIGS.db\n",
    "anvi-display-contigs-stats --report-as-text -o ./02_ASSEMBLY_BINNING/stats_mock_metagenome_spades.txt ./02_ASSEMBLY_BINNING/mock_metagenome_spades-CONTIGS.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c65d1b5-efc6-413b-ad86-62354b6bfc5b",
   "metadata": {},
   "source": [
    "`anvi-script-reformat-fasta --simplify-names`: anvio script to reformat contig names for a consistent nomenclature  \n",
    "`anvi-gen-contigs-database`: anvio works with SQL databases to store information about contigs, databases are generated by first predicting open reading frames \n",
    "`anvi-run-hmms -c -I -T 6`: generated contig databases are screened for collections of single-copy-marker genes and 16S rRNA genes\n",
    "`-f / -n /-o`: Specify input, give the database a name, define output  \n",
    "`anvi-display-contigs-stats`: Script that generates basic contig statistics (similar to `QUAST` in a way...) and that predicts the number of genomes present in the contigs database  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff0c1f4-1292-445c-a80c-fc53a369c9aa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>QUESTION/TASK:</b> \n",
    "<ul>\n",
    "  <li>Have a look at the generated stats .txt files, how many genomes can we expect?</li>\n",
    "  <li>What resources did anvio use for its estimation of the number of genomes?</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079cd3b8-bc56-4e32-b2d6-26a8daa8c0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contigs_db      mock_metagenome_megahit\n",
      "Total Length    44253132\n",
      "Num Contigs     1619\n",
      "Num Contigs > 100 kb    118\n",
      "Num Contigs > 50 kb     256\n",
      "Num Contigs > 20 kb     462\n",
      "Num Contigs > 10 kb     608\n",
      "Num Contigs > 5 kb      738\n",
      "Num Contigs > 2.5 kb    897\n",
      "Longest Contig  684728\n",
      "Shortest Contig 200\n",
      "Num Genes (prodigal)    40094\n",
      "L50     101\n",
      "L75     250\n",
      "L90     448\n",
      "N50     112798\n",
      "N75     51378\n",
      "N90     21180\n",
      "Archaea_76      459\n",
      "Bacteria_71     603\n",
      "Ribosomal_RNA_16S       6\n",
      "bacteria (Bacteria_71)  10\n",
      "archaea (Archaea_76)    3\n"
     ]
    }
   ],
   "source": [
    "### Check out the stats\n",
    "less ./02_ASSEMBLY_BINNING/stats_mock_metagenome_megahit.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8f4d7-05d9-4c8e-a950-c23718f8d72d",
   "metadata": {},
   "source": [
    "## Session 03 | Automated binning with METAWRAP and human-augmented binning with VIZBIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a3bb1f-3f26-4f0f-9cb9-6241c4f74ef3",
   "metadata": {},
   "source": [
    "### Introduction to binning\n",
    "\n",
    "We assembled contigs, and based on the carried out screening with [`anvio`] our assembly contains bacterial as well as archaeal MAGs (metagenome-assembled genomes). A MAG is commonly defined as a genome that is reconstructed/recovered from a metagenome through assembly and binning. We did the assembly, what about binning? Binning aims at identifying and putting together contigs that belong to a population, a group of co-existing microbes whose genomes are sufficiently similar that genome assemblages from this population map to the same reference genome.\n",
    "\n",
    "<img src=\"img/binning_lego1.png\" alt=\"Assembly done\" width=\"500\"/>\n",
    "\n",
    "<font size=\"2\"> We did the assembly, binning is next. © Rena Sophie Andräs </font>\n",
    "\n",
    "What kind of information can we use to identify populations of contigs that belong together?\n",
    "\n",
    "_Sequence composition-based:_\n",
    "* GC-content\n",
    "* k-mer frequencies\n",
    "\n",
    "_Reference-based:_\n",
    "* presence/absence of marker genes\n",
    "\n",
    "_Intra-sample coherence:_\n",
    "* differential coverage information\n",
    "\n",
    "**IDEALLY WE WANT TO COMBINE AS MUCH INFORMATION AS POSSIBLE**\n",
    "\n",
    "In the metagenomics world people compare binning often with either confetti or LEGO, we are obviously biased, but we prefer LEGO 😁!\n",
    "\n",
    "<img src=\"img/binning_lego2.png\" alt=\"Assembly done\" width=\"500\"/>\n",
    "\n",
    "<font size=\"2\"> LEGO is a great analogy in the context of metagenomics. © Rena Sophie Andräs </font>\n",
    "\n",
    "### Binning with METAWRAP\n",
    "\n",
    "For the binning process we will use [`METAWRAP`](https://github.com/bxlab/metaWRAP), or to be precise its implemented binning module. `METAWRAP` is a tool that \"wraps\" many different pieces of software together in the context of genome-resolved metagenomics. The strength of `METAWRAP` regarding binning is that it combines three individual binning tools:\n",
    "\n",
    "* [`CONCOCT`](https://github.com/BinPro/CONCOCT)\n",
    "* [`MAXBIN2`](https://sourceforge.net/projects/maxbin2/)\n",
    "* [`METABAT2`](https://bitbucket.org/berkeleylab/metabat/src/master/)\n",
    "\n",
    "All three make use of differential coverage information and sequence composition based on k-mer frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b05c6a51-8355-4b55-bdf5-e3e78f58fdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metawrap binning -o ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap -t 6 -a ./02_ASSEMBLY_BINNING/assembly_spades/contigs.fasta --metabat2 --maxbin2 --concoct ./00_READS/dataset_A_1.fastq ./00_READS/dataset_A_2.fastq ./00_READS/dataset_B_1.fastq ./00_READS/dataset_B_2.fastq\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                                           Entered read type: paired                                          -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                                  2 forward and 2 reverse read files detected                                 -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "########################################################################################################################\n",
      "#####                                     ALIGNING READS TO MAKE COVERAGE FILES                                    #####\n",
      "########################################################################################################################\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----               making copy of assembly file ./02_ASSEMBLY_BINNING/assembly_spades/contigs.fasta               -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                                            Indexing assembly file                                            -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "[bwa_index] Pack FASTA... 0.27 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[BWTIncCreate] textLength=88452466, availableWord=18223424\n",
      "[BWTIncConstructFromPacked] 10 iterations done. 30059730 characters processed.\n",
      "[BWTIncConstructFromPacked] 20 iterations done. 55531298 characters processed.\n",
      "[BWTIncConstructFromPacked] 30 iterations done. 78166482 characters processed.\n",
      "[bwt_gen] Finished constructing BWT in 35 iterations.\n",
      "[bwa_index] 17.19 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.25 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.15 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 7.84 sec\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa index ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/assembly.fa\n",
      "[main] Real time: 25.714 sec; CPU: 25.702 sec\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----            Aligning ./00_READS/dataset_A_1.fastq and ./00_READS/dataset_A_2.fastq back to assembly           -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation RF...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (2582, 3325, 4475)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (1, 8261)\n",
      "[M::mem_pestat] mean and std.dev: (3135.25, 1491.54)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (1, 10154)\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RF\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation RF...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (4235, 4262, 5749)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (1207, 8777)\n",
      "[M::mem_pestat] mean and std.dev: (4944.29, 836.09)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (1, 10291)\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RF\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation RF...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (4235, 4235, 4929)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (2847, 6317)\n",
      "[M::mem_pestat] mean and std.dev: (4676.44, 611.93)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (2153, 7124)\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RF\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation RF...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (2787, 4486, 5745)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (1, 11661)\n",
      "[M::mem_pestat] mean and std.dev: (4511.60, 1385.08)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (1, 14619)\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RF\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation RF...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (2457, 2457, 2457)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (2457, 2457)\n",
      "[M::mem_pestat] mean and std.dev: (2457.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (2457, 2457)\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RF\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -v 1 -t 6 ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/assembly.fa ./00_READS/dataset_A_1.fastq ./00_READS/dataset_A_2.fastq\n",
      "[main] Real time: 35.417 sec; CPU: 213.594 sec\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                                     Sorting the dataset_A alignment file                                     -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "[bam_sort_core] merging from 0 files and 6 in-memory blocks...\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----            Aligning ./00_READS/dataset_B_1.fastq and ./00_READS/dataset_B_2.fastq back to assembly           -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation RF...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (360, 2582, 3325)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (1, 9255)\n",
      "[M::mem_pestat] mean and std.dev: (2074.35, 1614.98)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (1, 12220)\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RF\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation RF...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (2787, 4235, 5745)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (1, 11661)\n",
      "[M::mem_pestat] mean and std.dev: (4441.00, 1701.48)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (1, 14619)\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RF\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation FF as there are not enough pairs\n",
      "[M::mem_pestat] analyzing insert size distribution for orientation FR...\n",
      "[M::mem_pestat] (25, 50, 75) percentile: (399, 399, 399)\n",
      "[M::mem_pestat] low and high boundaries for computing mean and std.dev: (399, 399)\n",
      "[M::mem_pestat] mean and std.dev: (399.00, 0.00)\n",
      "[M::mem_pestat] low and high boundaries for proper pairs: (399, 399)\n",
      "[M::mem_pestat] skip orientation RF as there are not enough pairs\n",
      "[M::mem_pestat] skip orientation RR as there are not enough pairs\n",
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem -v 1 -t 6 ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/assembly.fa ./00_READS/dataset_B_1.fastq ./00_READS/dataset_B_2.fastq\n",
      "[main] Real time: 30.986 sec; CPU: 180.469 sec\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                                     Sorting the dataset_B alignment file                                     -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "[bam_sort_core] merging from 0 files and 6 in-memory blocks...\n",
      "\n",
      "########################################################################################################################\n",
      "#####                                               RUNNING METABAT2                                               #####\n",
      "########################################################################################################################\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                                          making contig depth file...                                         -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Output depth matrix to ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/metabat_depth.txt\n",
      "Output matrix to ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/metabat_depth.txt\n",
      "Opening 2 bams\n",
      "Consolidating headers\n",
      "Processing bam files\n",
      "Thread 1 finished: dataset_B.bam with 3165117 reads and 3156758 readsWellMapped\n",
      "Thread 0 finished: dataset_A.bam with 3751123 reads and 3740871 readsWellMapped\n",
      "Creating depth matrix file: ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/metabat_depth.txt\n",
      "Closing most bam files\n",
      "Closing last bam file\n",
      "Finished\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                                       Starting binning with metaBAT2...                                      -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "MetaBAT 2 (v2.12.1) using minContig 1500, minCV 1.0, minCVSum 1.0, maxP 95%, minS 60, and maxEdges 200. \n",
      "10 bins (42298797 bases in total) formed.\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                              metaBAT2 finished successfully, and found 11 bins!                              -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "########################################################################################################################\n",
      "#####                                                RUNNING MAXBIN2                                               #####\n",
      "########################################################################################################################\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                                          making contig depth file...                                         -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Output depth matrix to ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/mb2_master_depth.txt\n",
      "Calculating intra contig depth variance\n",
      "Output matrix to ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/mb2_master_depth.txt\n",
      "Opening 2 bams\n",
      "Consolidating headers\n",
      "Processing bam files\n",
      "Thread 1 finished: dataset_B.bam with 3165117 reads and 3156758 readsWellMapped\n",
      "Thread 0 finished: dataset_A.bam with 3751123 reads and 3740871 readsWellMapped\n",
      "Creating depth matrix file: ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/mb2_master_depth.txt\n",
      "Closing most bam files\n",
      "Closing last bam file\n",
      "Finished\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                    split master contig depth file into individual files for maxbin2 input                    -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "processing dataset_A.bam depth file...\n",
      "processing dataset_B.bam depth file...\n",
      "MaxBin 2.2.6\n",
      "No Contig file. Please specify contig file by -contig\n",
      "MaxBin - a metagenomics binning software.\n",
      "Usage:\n",
      "  run_MaxBin.pl\n",
      "    -contig (contig file)\n",
      "    -out (output file)\n",
      "\n",
      "   (Input reads and abundance information)\n",
      "    [-reads (reads file) -reads2 (readsfile) -reads3 (readsfile) -reads4 ... ]\n",
      "    [-abund (abundance file) -abund2 (abundfile) -abund3 (abundfile) -abund4 ... ]\n",
      "\n",
      "   (You can also input lists consisting of reads and abundance files)\n",
      "    [-reads_list (list of reads files)]\n",
      "    [-abund_list (list of abundance files)]\n",
      "\n",
      "   (Other parameters)\n",
      "    [-min_contig_length (minimum contig length. Default 1000)]\n",
      "    [-max_iteration (maximum Expectation-Maximization algorithm iteration number. Default 50)]\n",
      "    [-thread (thread num; default 1)]\n",
      "    [-prob_threshold (probability threshold for EM final classification. Default 0.9)]\n",
      "    [-plotmarker]\n",
      "    [-markerset (marker gene sets, 107 (default) or 40.  See README for more information.)]\n",
      "\n",
      "  (for debug purpose)\n",
      "    [-version] [-v] (print version number)\n",
      "    [-verbose]\n",
      "    [-preserve_intermediate]\n",
      "\n",
      "  Please specify either -reads or -abund information.\n",
      "  You can input multiple reads and/or abundance files at the same time.\n",
      "  Please read README file for more details.\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                                       Starting binning with MaxBin2...                                       -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "MaxBin 2.2.6\n",
      "Input contig: ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/assembly.fa\n",
      "Thread: 6\n",
      "Min contig length: 1000\n",
      "out header: ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin\n",
      "Located abundance file [/home/lu87neb/data/MBGW223/./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/mb2_dataset_A.txt]\n",
      "Located abundance file [/home/lu87neb/data/MBGW223/./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/mb2_dataset_B.txt]\n",
      "Searching against 107 marker genes to find starting seed contigs for [./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/assembly.fa]...\n",
      "Running FragGeneScan....\n",
      "Running HMMER hmmsearch....\n",
      "Done data collection. Running MaxBin...\n",
      "Command: /data/mambaforge/envs/metawrap/opt/MaxBin-2.2.6/src/MaxBin -fasta ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.contig.tmp  -abund ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.contig.tmp.abund1 -abund2 ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.contig.tmp.abund2 -seed ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.seed -out ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin -min_contig_length 1000 -thread 6\n",
      "Minimum contig length set to 1000.\n",
      "Reading seed list...\n",
      "Looking for seeds in sequences.\n",
      "\tNODE_1_length_925458_cov_9.567712 [5.023360] [10.017200]\n",
      "\tNODE_7_length_451780_cov_9.516290 [9.911200] [5.056010]\n",
      "\tNODE_45_length_205120_cov_20.850716 [19.920800] [12.701900]\n",
      "\tNODE_47_length_202202_cov_9.608305 [4.917550] [9.909530]\n",
      "\tNODE_101_length_116674_cov_15.829127 [14.841500] [10.028300]\n",
      "\tNODE_173_length_71859_cov_15.907303 [20.148200] [4.895810]\n",
      "\tNODE_617_length_7112_cov_16.268103 [15.423200] [10.095100]\n",
      "Get 7 seeds.\n",
      "\n",
      "Start EM process.\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "\n",
      "EM finishes successfully.\n",
      "\n",
      "Classifying sequences based on the EM result.\n",
      "Minimum probability for binning: 0.50\n",
      "Ignoring 0 bins without any sequences.\n",
      "Number of unclassified sequences: 2 (0.23%)\n",
      "Elapsed time:  0 days 00:00:03\n",
      "Done data collection. Running MaxBin...\n",
      "Command: /data/mambaforge/envs/metawrap/opt/MaxBin-2.2.6/src/MaxBin -fasta ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.0004.fasta  -abund ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.contig.tmp.abund1 -abund2 ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.contig.tmp.abund2 -seed ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.0004.out.seed -out ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.0004.out -min_contig_length 1000 -thread 6\n",
      "Minimum contig length set to 1000.\n",
      "Reading seed list...\n",
      "Looking for seeds in sequences.\n",
      "\tNODE_1_length_925458_cov_9.567712 [5.023360] [10.017200]\n",
      "\tNODE_47_length_202202_cov_9.608305 [4.917550] [9.909530]\n",
      "Get 2 seeds.\n",
      "\n",
      "Start EM process.\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "\n",
      "EM finishes successfully.\n",
      "\n",
      "Classifying sequences based on the EM result.\n",
      "Minimum probability for binning: 0.50\n",
      "Ignoring 0 bins without any sequences.\n",
      "Number of unclassified sequences: 0 (0.00%)\n",
      "Elapsed time:  0 days 00:00:00\n",
      "Done data collection. Running MaxBin...\n",
      "Command: /data/mambaforge/envs/metawrap/opt/MaxBin-2.2.6/src/MaxBin -fasta ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.0007.fasta  -abund ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.contig.tmp.abund1 -abund2 ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.contig.tmp.abund2 -seed ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.0007.out.seed -out ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.0007.out -min_contig_length 1000 -thread 6\n",
      "Minimum contig length set to 1000.\n",
      "Reading seed list...\n",
      "Looking for seeds in sequences.\n",
      "\tNODE_2_length_684733_cov_15.923411 [20.063300] [4.986370]\n",
      "\tNODE_286_length_41621_cov_18.131261 [15.100600] [10.016500]\n",
      "Get 2 seeds.\n",
      "\n",
      "Start EM process.\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "\n",
      "EM finishes successfully.\n",
      "\n",
      "Classifying sequences based on the EM result.\n",
      "Minimum probability for binning: 0.50\n",
      "Ignoring 0 bins without any sequences.\n",
      "Number of unclassified sequences: 0 (0.00%)\n",
      "Elapsed time:  0 days 00:00:01\n",
      "\n",
      "\n",
      "\n",
      "bin.001.marker.fasta\n",
      "bin.002.marker.fasta\n",
      "bin.003.marker.fasta\n",
      "bin.004.marker.fasta\n",
      "bin.005.marker.fasta\n",
      "bin.006.marker.fasta\n",
      "bin.007.marker.fasta\n",
      "bin.008.marker.fasta\n",
      "bin.009.marker.fasta\n",
      "Deleting intermediate files.\n",
      "\n",
      "\n",
      "========== Job finished ==========\n",
      "Yielded 9 bins for contig (scaffold) file ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/assembly.fa\n",
      "\n",
      "Here are the output files for this run.\n",
      "Please refer to the README file for further details.\n",
      "\n",
      "Summary file: ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.summary\n",
      "Genome abundance info file: ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.abundance\n",
      "Marker counts: ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.marker\n",
      "Marker genes for each bin: ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.marker_of_each_gene.tar.gz\n",
      "Bin files: ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.001.fasta - ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.009.fasta\n",
      "Unbinned sequences: ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/maxbin2_out/bin.noclass\n",
      "\n",
      "\n",
      "========== Elapsed Time ==========\n",
      "0 hours 0 minutes and 25 seconds.\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                               MaxBin2 finished successfully, and found 9 bins!                               -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "########################################################################################################################\n",
      "#####                                                RUNNING CONCOCT                                               #####\n",
      "########################################################################################################################\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                                       indexing .bam alignment files...                                       -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/dataset_A.bam\n",
      "./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/dataset_B.bam\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                             cutting up contigs into 10kb fragments for CONCOCT...                            -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                                    estimating contig fragment coverage...                                    -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "/data/mambaforge/envs/metawrap/bin/concoct_coverage_table.py:48: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  df = pd.read_table(fh, header=None)\n",
      "usage: concoct [-h] [--coverage_file COVERAGE_FILE]\n",
      "               [--composition_file COMPOSITION_FILE] [-c CLUSTERS]\n",
      "               [-k KMER_LENGTH] [-t THREADS] [-l LENGTH_THRESHOLD]\n",
      "               [-r READ_LENGTH] [--total_percentage_pca TOTAL_PERCENTAGE_PCA]\n",
      "               [-b BASENAME] [-s SEED] [-i ITERATIONS] [-e EPSILON]\n",
      "               [--no_cov_normalization] [--no_total_coverage]\n",
      "               [--no_original_data] [-o] [-d] [-v]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --coverage_file COVERAGE_FILE\n",
      "                        specify the coverage file, containing a table where\n",
      "                        each row correspond to a contig, and each column\n",
      "                        correspond to a sample. The values are the average\n",
      "                        coverage for this contig in that sample. All values\n",
      "                        are separated with tabs.\n",
      "  --composition_file COMPOSITION_FILE\n",
      "                        specify the composition file, containing sequences in\n",
      "                        fasta format. It is named the composition file since\n",
      "                        it is used to calculate the kmer composition (the\n",
      "                        genomic signature) of each contig.\n",
      "  -c CLUSTERS, --clusters CLUSTERS\n",
      "                        specify maximal number of clusters for VGMM, default\n",
      "                        400.\n",
      "  -k KMER_LENGTH, --kmer_length KMER_LENGTH\n",
      "                        specify kmer length, default 4.\n",
      "  -t THREADS, --threads THREADS\n",
      "                        Number of threads to use\n",
      "  -l LENGTH_THRESHOLD, --length_threshold LENGTH_THRESHOLD\n",
      "                        specify the sequence length threshold, contigs shorter\n",
      "                        than this value will not be included. Defaults to\n",
      "                        1000.\n",
      "  -r READ_LENGTH, --read_length READ_LENGTH\n",
      "                        specify read length for coverage, default 100\n",
      "  --total_percentage_pca TOTAL_PERCENTAGE_PCA\n",
      "                        The percentage of variance explained by the principal\n",
      "                        components for the combined data.\n",
      "  -b BASENAME, --basename BASENAME\n",
      "                        Specify the basename for files or directory where\n",
      "                        outputwill be placed. Path to existing directory or\n",
      "                        basenamewith a trailing '/' will be interpreted as a\n",
      "                        directory.If not provided, current directory will be\n",
      "                        used.\n",
      "  -s SEED, --seed SEED  Specify an integer to use as seed for clustering. 0\n",
      "                        gives a random seed, 1 is the default seed and any\n",
      "                        other positive integer can be used. Other values give\n",
      "                        ArgumentTypeError.\n",
      "  -i ITERATIONS, --iterations ITERATIONS\n",
      "                        Specify maximum number of iterations for the VBGMM.\n",
      "                        Default value is 500\n",
      "  -e EPSILON, --epsilon EPSILON\n",
      "                        Specify the epsilon for VBGMM. Default value is 1.0e-6\n",
      "  --no_cov_normalization\n",
      "                        By default the coverage is normalized with regards to\n",
      "                        samples, then normalized with regards of contigs and\n",
      "                        finally log transformed. By setting this flag you skip\n",
      "                        the normalization and only do log transorm of the\n",
      "                        coverage.\n",
      "  --no_total_coverage   By default, the total coverage is added as a new\n",
      "                        column in the coverage data matrix, independently of\n",
      "                        coverage normalization but previous to log\n",
      "                        transformation. Use this tag to escape this behaviour.\n",
      "  --no_original_data    By default the original data is saved to disk. For big\n",
      "                        datasets, especially when a large k is used for\n",
      "                        compositional data, this file can become very large.\n",
      "                        Use this tag if you don't want to save the original\n",
      "                        data.\n",
      "  -o, --converge_out    Write convergence info to files.\n",
      "  -d, --debug           Debug parameters.\n",
      "  -v, --version         show program's version number and exit\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                                       Starting binning with CONCOCT...                                       -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Up and running. Check /data/lu87neb/MBGW223/02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/work_files/concoct_out/log.txt for progress\n",
      "/data/mambaforge/envs/metawrap/lib/python2.7/site-packages/concoct/input.py:82: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  cov = p.read_table(cov_file, header=0, index_col=0)\n",
      "4330 136 6\n",
      "Setting 6 OMP threads\n",
      "Generate input data\n",
      "0,-33112.699480,1581.247497\n",
      "1,-29912.852208,3199.847273\n",
      "2,-26632.835922,3280.016286\n",
      "3,-24587.958316,2044.877605\n",
      "4,-23376.770155,1211.188161\n",
      "5,-22622.564776,754.205378\n",
      "6,-22119.643397,502.921379\n",
      "7,-21824.396333,295.247064\n",
      "8,-21673.552937,150.843396\n",
      "9,-21616.424702,57.128235\n",
      "10,-21556.080288,60.344414\n",
      "11,-21522.540152,33.540137\n",
      "12,-21507.617096,14.923055\n",
      "13,-21479.058049,28.559047\n",
      "14,-21440.016805,39.041244\n",
      "15,-21400.465760,39.551045\n",
      "16,-21365.193182,35.272579\n",
      "17,-21336.051044,29.142137\n",
      "18,-21292.147490,43.903554\n",
      "19,-21261.530610,30.616880\n",
      "20,-21240.482933,21.047677\n",
      "21,-21232.676061,7.806872\n",
      "22,-21231.186059,1.490002\n",
      "23,-21228.702928,2.483131\n",
      "24,-21226.272360,2.430568\n",
      "25,-21220.222739,6.049621\n",
      "26,-21220.071808,0.150931\n",
      "27,-21219.967420,0.104388\n",
      "28,-21219.894725,0.072695\n",
      "29,-21219.847841,0.046885\n",
      "30,-21219.819955,0.027886\n",
      "31,-21219.805145,0.014810\n",
      "32,-21219.799060,0.006085\n",
      "33,-21219.798609,0.000451\n",
      "34,-21219.801699,0.003090\n",
      "35,-21219.806882,0.005183\n",
      "36,-21219.813220,0.006338\n",
      "37,-21219.820097,0.006877\n",
      "38,-21219.827119,0.007022\n",
      "39,-21219.834039,0.006920\n",
      "40,-21219.840709,0.006671\n",
      "41,-21219.847050,0.006341\n",
      "42,-21219.853024,0.005973\n",
      "43,-21219.858620,0.005596\n",
      "44,-21219.863845,0.005225\n",
      "45,-21219.868716,0.004872\n",
      "46,-21219.873271,0.004555\n",
      "47,-21219.877512,0.004241\n",
      "48,-21219.881450,0.003938\n",
      "49,-21219.885142,0.003692\n",
      "50,-21219.888600,0.003458\n",
      "51,-21219.891852,0.003252\n",
      "52,-21219.894900,0.003047\n",
      "53,-21219.897775,0.002875\n",
      "54,-21219.900469,0.002695\n",
      "55,-21219.903018,0.002549\n",
      "56,-21219.905417,0.002399\n",
      "57,-21219.907665,0.002248\n",
      "58,-21219.909780,0.002114\n",
      "59,-21219.911763,0.001984\n",
      "60,-21219.913630,0.001867\n",
      "61,-21219.915361,0.001731\n",
      "62,-21219.916969,0.001608\n",
      "63,-21219.918462,0.001493\n",
      "64,-21219.919818,0.001355\n",
      "65,-21219.921058,0.001240\n",
      "66,-21219.922194,0.001136\n",
      "67,-21219.923188,0.000994\n",
      "68,-21219.924077,0.000889\n",
      "69,-21219.924826,0.000749\n",
      "70,-21219.925458,0.000631\n",
      "71,-21219.925954,0.000496\n",
      "72,-21219.926329,0.000375\n",
      "73,-21219.926592,0.000263\n",
      "74,-21219.926728,0.000136\n",
      "75,-21219.926755,0.000027\n",
      "CONCOCT Finished, the log shows how it went.\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                                   merging 10kb fragments back into contigs                                   -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "NODE_402_length_23935_cov_9.669472\t[('2', 2)]\n",
      "NODE_45_length_205120_cov_20.850716\t[('1', 20)]\n",
      "NODE_147_length_85899_cov_20.506838\t[('1', 8)]\n",
      "NODE_407_length_23531_cov_16.368632\t[('8', 2)]\n",
      "NODE_362_length_29058_cov_15.920836\t[('3', 1), ('2', 1)], chosen: 3\n",
      "NODE_126_length_98281_cov_9.634455\t[('0', 9)]\n",
      "NODE_178_length_70054_cov_20.910799\t[('1', 7)]\n",
      "NODE_112_length_109396_cov_20.446484\t[('1', 10)]\n",
      "NODE_267_length_45643_cov_15.784746\t[('8', 4)]\n",
      "NODE_296_length_39789_cov_8.347360\t[('3', 3)]\n",
      "NODE_430_length_20623_cov_16.899699\t[('9', 1), ('2', 1)], chosen: 9\n",
      "NODE_331_length_32883_cov_21.871817\t[('1', 3)]\n",
      "NODE_252_length_49252_cov_16.696364\t[('8', 3), ('5', 1)], chosen: 8\n",
      "NODE_186_length_67995_cov_9.467133\t[('0', 6)]\n",
      "NODE_292_length_40794_cov_9.123911\t[('9', 4)]\n",
      "NODE_1_length_925458_cov_9.567712\t[('3', 16), ('5', 76)], chosen: 5\n",
      "NODE_145_length_86494_cov_20.660512\t[('1', 8)]\n",
      "NODE_14_length_376829_cov_21.048974\t[('1', 37)]\n",
      "NODE_60_length_171419_cov_9.654198\t[('1', 1), ('0', 16)], chosen: 0\n",
      "NODE_346_length_31241_cov_8.838870\t[('3', 3)]\n",
      "NODE_157_length_82088_cov_16.187498\t[('9', 1), ('2', 7)], chosen: 2\n",
      "NODE_411_length_23297_cov_15.505722\t[('5', 2)]\n",
      "NODE_130_length_95449_cov_9.614819\t[('9', 9)]\n",
      "NODE_115_length_106856_cov_16.819206\t[('9', 1), ('2', 9)], chosen: 2\n",
      "NODE_279_length_42569_cov_21.378722\t[('1', 4)]\n",
      "NODE_308_length_36599_cov_16.265789\t[('2', 3)]\n",
      "NODE_271_length_44968_cov_9.291430\t[('0', 4)]\n",
      "NODE_51_length_193089_cov_15.974569\t[('8', 19)]\n",
      "NODE_371_length_27791_cov_9.366022\t[('0', 2)]\n",
      "NODE_353_length_30141_cov_16.868244\t[('2', 3)]\n",
      "NODE_387_length_25980_cov_8.164474\t[('3', 2)]\n",
      "NODE_364_length_28948_cov_21.836569\t[('3', 1), ('6', 1)], chosen: 3\n",
      "NODE_383_length_26355_cov_8.336008\t[('3', 2)]\n",
      "NODE_161_length_80278_cov_20.555614\t[('1', 8)]\n",
      "NODE_56_length_177959_cov_16.264637\t[('8', 17)]\n",
      "NODE_98_length_117169_cov_15.799964\t[('8', 10), ('0', 1)], chosen: 8\n",
      "NODE_245_length_50967_cov_20.813227\t[('1', 5)]\n",
      "NODE_194_length_65448_cov_16.797884\t[('2', 6)]\n",
      "NODE_128_length_96926_cov_20.914443\t[('1', 9)]\n",
      "NODE_366_length_28814_cov_7.999061\t[('3', 2)]\n",
      "NODE_391_length_25056_cov_18.780849\t[('2', 2)]\n",
      "NODE_214_length_59461_cov_23.409302\t[('1', 5)]\n",
      "NODE_241_length_52205_cov_18.394669\t[('3', 1), ('2', 4)], chosen: 2\n",
      "NODE_13_length_396998_cov_20.768120\t[('1', 39)]\n",
      "NODE_236_length_53907_cov_9.447820\t[('9', 5)]\n",
      "NODE_374_length_27382_cov_9.592125\t[('0', 2)]\n",
      "NODE_66_length_161112_cov_20.857044\t[('1', 16)]\n",
      "NODE_88_length_125585_cov_15.999124\t[('8', 12)]\n",
      "NODE_107_length_112478_cov_9.627069\t[('0', 11)]\n",
      "NODE_20_length_334201_cov_20.942370\t[('1', 33)]\n",
      "NODE_21_length_327063_cov_9.452206\t[('9', 31), ('2', 1)], chosen: 9\n",
      "NODE_92_length_121837_cov_9.620675\t[('0', 12)]\n",
      "NODE_273_length_44516_cov_16.198803\t[('9', 1), ('2', 3)], chosen: 2\n",
      "NODE_28_length_264985_cov_9.674314\t[('9', 19), ('3', 2), ('2', 5)], chosen: 9\n",
      "NODE_210_length_61199_cov_16.954926\t[('3', 1), ('2', 5)], chosen: 2\n",
      "NODE_256_length_48760_cov_16.904301\t[('2', 4)]\n",
      "NODE_5_length_529571_cov_19.373639\t[('3', 2), ('6', 50)], chosen: 6\n",
      "NODE_396_length_24471_cov_15.485952\t[('2', 2)]\n",
      "NODE_433_length_20019_cov_7.766981\t[('3', 2)]\n",
      "NODE_184_length_68175_cov_8.338403\t[('3', 6)]\n",
      "NODE_97_length_117597_cov_9.492190\t[('9', 10), ('2', 1)], chosen: 9\n",
      "NODE_65_length_161337_cov_15.956300\t[('8', 16)]\n",
      "NODE_208_length_61597_cov_16.182380\t[('2', 6)]\n",
      "NODE_62_length_166074_cov_20.795301\t[('1', 16)]\n",
      "NODE_53_length_185595_cov_9.479934\t[('0', 18)]\n",
      "NODE_239_length_52829_cov_17.253553\t[('2', 5)]\n",
      "NODE_82_length_132983_cov_9.500940\t[('9', 10), ('2', 3)], chosen: 9\n",
      "NODE_397_length_24411_cov_8.522828\t[('3', 2)]\n",
      "NODE_177_length_70435_cov_8.404291\t[('3', 7)]\n",
      "NODE_35_length_224269_cov_9.684418\t[('9', 18), ('2', 4)], chosen: 9\n",
      "NODE_342_length_31697_cov_17.108653\t[('2', 3)]\n",
      "NODE_373_length_27430_cov_15.914447\t[('2', 2)]\n",
      "NODE_221_length_57777_cov_9.325093\t[('9', 4), ('2', 1)], chosen: 9\n",
      "NODE_57_length_175722_cov_9.637889\t[('9', 15), ('3', 1), ('2', 1)], chosen: 9\n",
      "NODE_9_length_409053_cov_9.542196\t[('0', 40)]\n",
      "NODE_100_length_116977_cov_15.876841\t[('2', 11)]\n",
      "NODE_174_length_71819_cov_9.483543\t[('0', 7)]\n",
      "NODE_421_length_21878_cov_8.638088\t[('3', 2)]\n",
      "NODE_155_length_82778_cov_9.589377\t[('9', 8)]\n",
      "NODE_392_length_24965_cov_8.003011\t[('3', 2)]\n",
      "NODE_305_length_37109_cov_15.881686\t[('8', 3)]\n",
      "NODE_320_length_34506_cov_16.953760\t[('2', 3)]\n",
      "NODE_87_length_130841_cov_19.274158\t[('6', 13)]\n",
      "NODE_419_length_21964_cov_7.955498\t[('3', 2)]\n",
      "NODE_114_length_107186_cov_16.197889\t[('8', 10)]\n",
      "NODE_140_length_88325_cov_9.830112\t[('9', 8)]\n",
      "NODE_345_length_31314_cov_15.957260\t[('2', 3)]\n",
      "NODE_380_length_26877_cov_8.015957\t[('3', 2)]\n",
      "NODE_39_length_220389_cov_20.673019\t[('1', 22)]\n",
      "NODE_77_length_140870_cov_16.023321\t[('8', 12), ('5', 2)], chosen: 8\n",
      "NODE_274_length_43807_cov_9.546352\t[('9', 3), ('2', 1)], chosen: 9\n",
      "NODE_304_length_37129_cov_17.995469\t[('2', 2), ('4', 1)], chosen: 2\n",
      "NODE_165_length_78604_cov_9.528485\t[('9', 7)]\n",
      "NODE_153_length_83763_cov_9.770333\t[('0', 8)]\n",
      "NODE_142_length_87810_cov_21.135149\t[('1', 8)]\n",
      "NODE_405_length_23562_cov_15.518782\t[('8', 2)]\n",
      "NODE_300_length_38798_cov_7.832512\t[('3', 3)]\n",
      "NODE_150_length_84796_cov_20.418145\t[('1', 8)]\n",
      "NODE_148_length_85460_cov_16.069879\t[('8', 8)]\n",
      "NODE_309_length_36392_cov_20.641247\t[('1', 3)]\n",
      "NODE_215_length_59174_cov_21.107969\t[('1', 5)]\n",
      "NODE_312_length_35859_cov_16.080410\t[('8', 3)]\n",
      "NODE_288_length_41390_cov_16.340607\t[('2', 4)]\n",
      "NODE_233_length_54433_cov_7.984847\t[('3', 5)]\n",
      "NODE_386_length_26042_cov_16.088621\t[('2', 2)]\n",
      "NODE_40_length_213186_cov_19.303968\t[('6', 21)]\n",
      "NODE_247_length_50929_cov_16.302689\t[('2', 5)]\n",
      "NODE_47_length_202202_cov_9.608305\t[('9', 15), ('2', 5)], chosen: 9\n",
      "NODE_303_length_37376_cov_18.110260\t[('2', 3)]\n",
      "NODE_321_length_34354_cov_8.172541\t[('3', 3)]\n",
      "NODE_201_length_62516_cov_8.132851\t[('3', 6)]\n",
      "NODE_73_length_143862_cov_18.973951\t[('6', 14)]\n",
      "NODE_416_length_22943_cov_21.320474\t[('2', 2)]\n",
      "NODE_269_length_45135_cov_16.978172\t[('2', 4)]\n",
      "NODE_32_length_232690_cov_9.528338\t[('0', 23)]\n",
      "NODE_357_length_29573_cov_19.005691\t[('2', 2)]\n",
      "NODE_133_length_93987_cov_16.084934\t[('8', 9)]\n",
      "NODE_90_length_123338_cov_20.847878\t[('1', 12)]\n",
      "NODE_71_length_151596_cov_9.459328\t[('0', 15)]\n",
      "NODE_385_length_26144_cov_20.440914\t[('1', 2)]\n",
      "NODE_382_length_26609_cov_21.294268\t[('1', 2)]\n",
      "NODE_227_length_56733_cov_20.471859\t[('1', 5)]\n",
      "NODE_44_length_206812_cov_9.479785\t[('0', 20)]\n",
      "NODE_378_length_27095_cov_20.679623\t[('1', 2)]\n",
      "NODE_199_length_63683_cov_17.460851\t[('9', 2), ('2', 4)], chosen: 2\n",
      "NODE_432_length_20307_cov_9.389739\t[('0', 2)]\n",
      "NODE_359_length_29316_cov_18.604661\t[('6', 2)]\n",
      "NODE_376_length_27306_cov_8.167627\t[('3', 2)]\n",
      "NODE_12_length_400258_cov_9.592874\t[('0', 40)]\n",
      "NODE_299_length_39064_cov_8.165834\t[('3', 3)]\n",
      "NODE_197_length_64256_cov_19.098815\t[('6', 6)]\n",
      "NODE_7_length_451780_cov_9.516290\t[('0', 45)]\n",
      "NODE_171_length_74440_cov_20.410674\t[('1', 7)]\n",
      "NODE_34_length_225646_cov_9.509449\t[('0', 22)]\n",
      "NODE_162_length_79676_cov_8.266274\t[('3', 7)]\n",
      "NODE_172_length_72004_cov_20.691462\t[('1', 7)]\n",
      "NODE_101_length_116674_cov_15.829127\t[('8', 11)]\n",
      "NODE_301_length_38751_cov_7.866730\t[('3', 3)]\n",
      "NODE_263_length_46308_cov_20.628435\t[('1', 4)]\n",
      "NODE_72_length_148025_cov_20.878185\t[('1', 14)]\n",
      "NODE_341_length_31810_cov_15.430137\t[('8', 3)]\n",
      "NODE_159_length_81375_cov_16.224115\t[('8', 8)]\n",
      "NODE_243_length_51054_cov_15.971666\t[('2', 5)]\n",
      "NODE_216_length_59092_cov_9.386351\t[('0', 5)]\n",
      "NODE_363_length_29012_cov_10.022654\t[('9', 2)]\n",
      "NODE_116_length_106687_cov_21.017753\t[('1', 10)]\n",
      "NODE_249_length_50058_cov_7.787033\t[('3', 5)]\n",
      "NODE_394_length_24890_cov_8.226938\t[('3', 2)]\n",
      "NODE_234_length_54182_cov_17.747538\t[('3', 1), ('2', 4)], chosen: 2\n",
      "NODE_307_length_36931_cov_9.425995\t[('0', 3)]\n",
      "NODE_15_length_375387_cov_19.048331\t[('3', 1), ('6', 36)], chosen: 6\n",
      "NODE_250_length_49786_cov_8.188776\t[('3', 4)]\n",
      "NODE_231_length_54858_cov_9.619437\t[('9', 5)]\n",
      "NODE_431_length_20428_cov_8.047072\t[('3', 2)]\n",
      "NODE_196_length_64791_cov_9.623239\t[('9', 6)]\n",
      "NODE_372_length_27460_cov_15.790148\t[('2', 2)]\n",
      "NODE_418_length_22153_cov_8.046656\t[('3', 2)]\n",
      "NODE_259_length_47186_cov_16.253145\t[('3', 1), ('2', 3)], chosen: 2\n",
      "NODE_276_length_42788_cov_16.052067\t[('8', 4)]\n",
      "NODE_424_length_21435_cov_7.679794\t[('3', 2)]\n",
      "NODE_25_length_273219_cov_20.769303\t[('1', 27)]\n",
      "NODE_134_length_93655_cov_20.951026\t[('1', 9)]\n",
      "NODE_223_length_57370_cov_15.592253\t[('2', 5)]\n",
      "NODE_164_length_79444_cov_17.168247\t[('2', 7)]\n",
      "NODE_379_length_26940_cov_7.838534\t[('3', 2)]\n",
      "NODE_111_length_110414_cov_15.918910\t[('8', 11)]\n",
      "NODE_248_length_50214_cov_9.365179\t[('0', 5)]\n",
      "NODE_129_length_96083_cov_8.242835\t[('3', 9)]\n",
      "NODE_110_length_110900_cov_9.448257\t[('0', 11)]\n",
      "NODE_24_length_300940_cov_19.021859\t[('3', 1), ('6', 29)], chosen: 6\n",
      "NODE_6_length_473906_cov_9.640756\t[('0', 47)]\n",
      "NODE_335_length_32652_cov_15.728871\t[('2', 3)]\n",
      "NODE_360_length_29209_cov_15.292035\t[('8', 1), ('5', 1)], chosen: 8\n",
      "NODE_314_length_35255_cov_17.395824\t[('2', 3)]\n",
      "NODE_81_length_133819_cov_7.958905\t[('3', 13)]\n",
      "NODE_203_length_62223_cov_16.246300\t[('2', 6)]\n",
      "NODE_244_length_50998_cov_15.971066\t[('2', 5)]\n",
      "NODE_206_length_61915_cov_19.351568\t[('6', 6)]\n",
      "NODE_254_length_49194_cov_7.985816\t[('3', 4)]\n",
      "NODE_89_length_125563_cov_9.623171\t[('9', 11), ('2', 1)], chosen: 9\n",
      "NODE_176_length_70888_cov_16.817910\t[('2', 7)]\n",
      "NODE_58_length_173675_cov_20.595219\t[('1', 17)]\n",
      "NODE_131_length_94848_cov_22.713681\t[('1', 9)]\n",
      "NODE_220_length_57997_cov_8.048117\t[('3', 5)]\n",
      "NODE_368_length_28008_cov_16.087397\t[('2', 2)]\n",
      "NODE_154_length_83001_cov_16.556941\t[('2', 8)]\n",
      "NODE_413_length_23143_cov_22.916450\t[('3', 2)]\n",
      "NODE_70_length_152365_cov_15.887374\t[('8', 15)]\n",
      "NODE_264_length_46084_cov_8.397923\t[('3', 4)]\n",
      "NODE_280_length_42562_cov_15.943915\t[('2', 4)]\n",
      "NODE_143_length_87794_cov_20.732730\t[('1', 7), ('7', 1)], chosen: 1\n",
      "NODE_389_length_25754_cov_15.633838\t[('2', 2)]\n",
      "NODE_11_length_402684_cov_20.736276\t[('1', 40)]\n",
      "NODE_192_length_66710_cov_7.793789\t[('3', 6)]\n",
      "NODE_17_length_361174_cov_20.855037\t[('1', 36)]\n",
      "NODE_41_length_211730_cov_9.579813\t[('3', 2), ('5', 19)], chosen: 5\n",
      "NODE_253_length_49231_cov_16.072861\t[('2', 4)]\n",
      "NODE_36_length_223754_cov_20.583315\t[('1', 22)]\n",
      "NODE_46_length_203084_cov_9.399465\t[('9', 19), ('2', 1)], chosen: 9\n",
      "NODE_311_length_36097_cov_17.260363\t[('2', 3)]\n",
      "NODE_78_length_140540_cov_8.079866\t[('3', 14)]\n",
      "NODE_84_length_132853_cov_20.899328\t[('1', 13)]\n",
      "NODE_211_length_60768_cov_9.679014\t[('9', 3), ('2', 3)], chosen: 9\n",
      "NODE_156_length_82195_cov_22.594607\t[('1', 8)]\n",
      "NODE_318_length_34690_cov_9.730850\t[('0', 3)]\n",
      "NODE_108_length_112342_cov_9.606339\t[('9', 11)]\n",
      "NODE_240_length_52404_cov_7.797971\t[('3', 5)]\n",
      "NODE_255_length_48987_cov_18.156748\t[('2', 4)]\n",
      "NODE_317_length_35140_cov_9.476158\t[('9', 3)]\n",
      "NODE_354_length_30136_cov_15.732755\t[('2', 3)]\n",
      "NODE_404_length_23787_cov_16.009523\t[('2', 2)]\n",
      "NODE_104_length_116191_cov_9.741243\t[('0', 11)]\n",
      "NODE_365_length_28925_cov_7.904919\t[('3', 2)]\n",
      "NODE_343_length_31582_cov_9.395978\t[('9', 2), ('2', 1)], chosen: 9\n",
      "NODE_298_length_39241_cov_15.469887\t[('2', 3)]\n",
      "NODE_183_length_68547_cov_15.938460\t[('8', 6)]\n",
      "NODE_384_length_26223_cov_16.008025\t[('2', 2)]\n",
      "NODE_52_length_189675_cov_21.867340\t[('1', 18)]\n",
      "NODE_37_length_221814_cov_9.363679\t[('0', 22)]\n",
      "NODE_137_length_91196_cov_9.684160\t[('8', 1), ('0', 8)], chosen: 0\n",
      "NODE_284_length_42153_cov_9.595444\t[('0', 4)]\n",
      "NODE_95_length_119183_cov_20.506355\t[('1', 11)]\n",
      "NODE_182_length_68565_cov_16.191724\t[('2', 6)]\n",
      "NODE_187_length_67825_cov_8.143854\t[('3', 6)]\n",
      "NODE_189_length_67314_cov_19.177998\t[('6', 6)]\n",
      "NODE_18_length_357990_cov_19.131432\t[('6', 35)]\n",
      "NODE_120_length_101234_cov_20.502535\t[('1', 10)]\n",
      "NODE_348_length_30843_cov_9.805086\t[('9', 3)]\n",
      "NODE_272_length_44845_cov_9.470842\t[('0', 4)]\n",
      "NODE_398_length_24185_cov_16.120680\t[('5', 2)]\n",
      "NODE_179_length_69299_cov_8.079631\t[('3', 5), ('6', 1)], chosen: 3\n",
      "NODE_426_length_21376_cov_22.702125\t[('1', 2)]\n",
      "NODE_283_length_42156_cov_15.629106\t[('2', 4)]\n",
      "NODE_127_length_97346_cov_9.632556\t[('0', 9)]\n",
      "NODE_291_length_41032_cov_9.713083\t[('9', 4)]\n",
      "NODE_401_length_23945_cov_7.978108\t[('3', 2)]\n",
      "NODE_324_length_33603_cov_18.555234\t[('2', 3)]\n",
      "NODE_49_length_196073_cov_20.728479\t[('1', 19)]\n",
      "NODE_132_length_94391_cov_7.989251\t[('3', 9)]\n",
      "NODE_204_length_62204_cov_7.939484\t[('3', 6)]\n",
      "NODE_409_length_23495_cov_8.406527\t[('3', 2)]\n",
      "NODE_390_length_25417_cov_17.073141\t[('9', 1), ('2', 1)], chosen: 9\n",
      "NODE_175_length_71637_cov_8.273155\t[('3', 7)]\n",
      "NODE_336_length_32596_cov_15.881165\t[('2', 3)]\n",
      "NODE_229_length_56216_cov_9.726323\t[('0', 5)]\n",
      "NODE_2_length_684733_cov_15.923411\t[('3', 67), ('5', 1)], chosen: 3\n",
      "NODE_99_length_117085_cov_9.571136\t[('0', 11)]\n",
      "NODE_10_length_406395_cov_9.519274\t[('0', 38), ('8', 2)], chosen: 0\n",
      "NODE_173_length_71859_cov_15.907303\t[('3', 7)]\n",
      "NODE_74_length_143375_cov_21.615867\t[('1', 14)]\n",
      "NODE_375_length_27366_cov_15.958405\t[('8', 2)]\n",
      "NODE_209_length_61564_cov_15.821229\t[('2', 6)]\n",
      "NODE_86_length_131918_cov_20.598629\t[('1', 13)]\n",
      "NODE_297_length_39499_cov_17.106455\t[('9', 1), ('2', 2)], chosen: 2\n",
      "NODE_4_length_539343_cov_20.664330\t[('1', 53)]\n",
      "NODE_125_length_98957_cov_16.372824\t[('9', 2), ('2', 7)], chosen: 2\n",
      "NODE_246_length_50936_cov_8.365185\t[('3', 5)]\n",
      "NODE_68_length_157936_cov_9.687638\t[('0', 14), ('5', 1)], chosen: 0\n",
      "NODE_195_length_65445_cov_8.258465\t[('3', 4), ('6', 2)], chosen: 3\n",
      "NODE_315_length_35183_cov_9.637440\t[('9', 3)]\n",
      "NODE_230_length_54903_cov_15.619603\t[('8', 5)]\n",
      "NODE_136_length_91844_cov_20.922267\t[('1', 9)]\n",
      "NODE_109_length_111573_cov_16.012357\t[('8', 11)]\n",
      "NODE_422_length_21789_cov_16.246756\t[('2', 2)]\n",
      "NODE_355_length_29837_cov_8.105198\t[('3', 2)]\n",
      "NODE_158_length_82071_cov_15.968738\t[('8', 8)]\n",
      "NODE_144_length_87015_cov_9.597068\t[('9', 5), ('2', 3)], chosen: 9\n",
      "NODE_332_length_32791_cov_16.101081\t[('8', 3)]\n",
      "NODE_224_length_57322_cov_20.044406\t[('3', 3), ('6', 2)], chosen: 3\n",
      "NODE_270_length_44968_cov_17.302162\t[('9', 1), ('2', 3)], chosen: 2\n",
      "NODE_226_length_56771_cov_9.529657\t[('9', 5)]\n",
      "NODE_260_length_46897_cov_17.465202\t[('2', 4)]\n",
      "NODE_61_length_170141_cov_20.546541\t[('1', 17)]\n",
      "NODE_152_length_83976_cov_17.191263\t[('2', 8)]\n",
      "NODE_218_length_58977_cov_16.123842\t[('9', 1), ('2', 4)], chosen: 2\n",
      "NODE_293_length_40160_cov_9.663533\t[('9', 2), ('2', 2)], chosen: 9\n",
      "NODE_334_length_32662_cov_9.608274\t[('0', 3)]\n",
      "NODE_185_length_68071_cov_20.558677\t[('1', 6)]\n",
      "NODE_277_length_42622_cov_20.629243\t[('1', 4)]\n",
      "NODE_323_length_33874_cov_21.320057\t[('1', 3)]\n",
      "NODE_193_length_65516_cov_9.679214\t[('0', 6)]\n",
      "NODE_377_length_27215_cov_15.495655\t[('2', 2)]\n",
      "NODE_91_length_121915_cov_9.313606\t[('0', 12)]\n",
      "NODE_350_length_30313_cov_20.520028\t[('1', 3)]\n",
      "NODE_151_length_84501_cov_9.511321\t[('0', 8)]\n",
      "NODE_395_length_24706_cov_7.952375\t[('3', 2)]\n",
      "NODE_352_length_30217_cov_8.502321\t[('3', 3)]\n",
      "NODE_358_length_29406_cov_20.615788\t[('1', 2)]\n",
      "NODE_388_length_25941_cov_21.473538\t[('9', 1), ('2', 1)], chosen: 9\n",
      "NODE_429_length_20874_cov_14.994764\t[('2', 2)]\n",
      "NODE_222_length_57601_cov_15.594863\t[('8', 5)]\n",
      "NODE_59_length_171523_cov_20.928599\t[('1', 17)]\n",
      "NODE_400_length_23964_cov_8.353591\t[('3', 2)]\n",
      "NODE_347_length_31171_cov_8.271307\t[('3', 3)]\n",
      "NODE_294_length_39917_cov_23.144925\t[('1', 3)]\n",
      "NODE_30_length_257060_cov_19.078555\t[('3', 1), ('6', 24)], chosen: 6\n",
      "NODE_55_length_178234_cov_9.415795\t[('9', 15), ('2', 2)], chosen: 9\n",
      "NODE_281_length_42487_cov_16.306231\t[('8', 4)]\n",
      "NODE_168_length_77585_cov_9.531085\t[('0', 7)]\n",
      "NODE_50_length_193706_cov_20.695566\t[('1', 19)]\n",
      "NODE_33_length_226899_cov_20.697757\t[('1', 22)]\n",
      "NODE_138_length_90922_cov_8.105880\t[('3', 9)]\n",
      "NODE_265_length_45829_cov_7.885306\t[('3', 4)]\n",
      "NODE_27_length_267158_cov_9.516415\t[('8', 3), ('7', 1), ('0', 22)], chosen: 0\n",
      "NODE_121_length_101150_cov_9.549701\t[('0', 10)]\n",
      "NODE_289_length_41329_cov_16.206595\t[('8', 4)]\n",
      "NODE_42_length_210555_cov_9.628290\t[('9', 21)]\n",
      "NODE_285_length_41667_cov_9.547270\t[('0', 4)]\n",
      "NODE_219_length_58133_cov_21.280709\t[('1', 5)]\n",
      "NODE_261_length_46573_cov_8.626876\t[('3', 4)]\n",
      "NODE_242_length_52067_cov_15.881547\t[('8', 5)]\n",
      "NODE_213_length_59771_cov_20.930186\t[('1', 5)]\n",
      "NODE_38_length_221484_cov_21.216498\t[('1', 22)]\n",
      "NODE_237_length_53568_cov_15.794573\t[('8', 5)]\n",
      "NODE_427_length_21350_cov_17.020146\t[('2', 2)]\n",
      "NODE_339_length_32326_cov_8.707570\t[('3', 3)]\n",
      "NODE_123_length_100677_cov_20.677407\t[('1', 10)]\n",
      "NODE_403_length_23817_cov_15.757764\t[('8', 2)]\n",
      "NODE_141_length_87936_cov_20.429456\t[('1', 8)]\n",
      "NODE_113_length_107582_cov_20.901132\t[('1', 10)]\n",
      "NODE_257_length_48370_cov_16.137638\t[('3', 2), ('2', 2)], chosen: 3\n",
      "NODE_19_length_334231_cov_19.081400\t[('3', 1), ('6', 32)], chosen: 6\n",
      "NODE_23_length_318163_cov_15.857520\t[('3', 30), ('4', 1)], chosen: 3\n",
      "NODE_212_length_60425_cov_18.861603\t[('6', 6)]\n",
      "NODE_333_length_32751_cov_16.952135\t[('2', 3)]\n",
      "NODE_54_length_182572_cov_20.583836\t[('1', 18)]\n",
      "NODE_302_length_37462_cov_18.099046\t[('2', 3)]\n",
      "NODE_166_length_78275_cov_7.670187\t[('3', 7)]\n",
      "NODE_349_length_30803_cov_16.424190\t[('2', 3)]\n",
      "NODE_367_length_28680_cov_8.463686\t[('3', 2)]\n",
      "NODE_337_length_32377_cov_25.549131\t[('1', 3)]\n",
      "NODE_135_length_92593_cov_16.182855\t[('8', 9)]\n",
      "NODE_198_length_63814_cov_9.262881\t[('0', 6)]\n",
      "NODE_417_length_22872_cov_8.564667\t[('3', 1), ('6', 1)], chosen: 3\n",
      "NODE_415_length_23023_cov_20.977360\t[('1', 2)]\n",
      "NODE_322_length_34085_cov_15.758331\t[('8', 3)]\n",
      "NODE_188_length_67330_cov_9.648309\t[('9', 5), ('2', 1)], chosen: 9\n",
      "NODE_235_length_54015_cov_8.897572\t[('3', 5)]\n",
      "NODE_69_length_155722_cov_9.402667\t[('5', 15)]\n",
      "NODE_85_length_132556_cov_9.504268\t[('9', 13)]\n",
      "NODE_207_length_61636_cov_7.823826\t[('3', 6)]\n",
      "NODE_106_length_112798_cov_9.567388\t[('8', 1), ('0', 10)], chosen: 0\n",
      "NODE_105_length_113899_cov_20.603976\t[('1', 11)]\n",
      "NODE_329_length_32932_cov_9.770235\t[('0', 3)]\n",
      "NODE_139_length_90520_cov_20.615177\t[('1', 9)]\n",
      "NODE_238_length_53524_cov_16.378350\t[('2', 5)]\n",
      "NODE_202_length_62390_cov_23.499960\t[('1', 6)]\n",
      "NODE_393_length_24964_cov_15.498093\t[('8', 2)]\n",
      "NODE_122_length_100978_cov_20.685334\t[('1', 10)]\n",
      "NODE_325_length_33556_cov_15.974478\t[('2', 3)]\n",
      "NODE_381_length_26662_cov_9.275830\t[('9', 1), ('2', 1)], chosen: 9\n",
      "NODE_282_length_42178_cov_9.583719\t[('9', 4)]\n",
      "NODE_338_length_32326_cov_9.888817\t[('9', 2), ('3', 1)], chosen: 9\n",
      "NODE_258_length_47806_cov_7.773994\t[('3', 4)]\n",
      "NODE_79_length_139651_cov_20.960085\t[('1', 13)]\n",
      "NODE_80_length_136505_cov_15.903422\t[('8', 12), ('5', 1)], chosen: 8\n",
      "NODE_67_length_157937_cov_20.669392\t[('1', 15)]\n",
      "NODE_124_length_99235_cov_21.069863\t[('1', 9)]\n",
      "NODE_96_length_117770_cov_15.654895\t[('8', 11)]\n",
      "NODE_268_length_45172_cov_15.422524\t[('2', 4)]\n",
      "NODE_217_length_58991_cov_21.127851\t[('1', 5)]\n",
      "NODE_399_length_23978_cov_7.915186\t[('3', 1), ('6', 1)], chosen: 3\n",
      "NODE_420_length_21923_cov_20.085787\t[('1', 2)]\n",
      "NODE_356_length_29716_cov_15.319881\t[('2', 2)]\n",
      "NODE_286_length_41621_cov_18.131261\t[('2', 4)]\n",
      "NODE_310_length_36117_cov_16.219178\t[('9', 2), ('8', 1)], chosen: 9\n",
      "NODE_118_length_103773_cov_21.117482\t[('1', 10)]\n",
      "NODE_428_length_21244_cov_8.156496\t[('3', 2)]\n",
      "NODE_326_length_33450_cov_9.654978\t[('0', 3)]\n",
      "NODE_225_length_56963_cov_7.996363\t[('3', 5)]\n",
      "NODE_191_length_66756_cov_8.698085\t[('3', 6)]\n",
      "NODE_83_length_132867_cov_9.569542\t[('9', 13)]\n",
      "NODE_228_length_56712_cov_9.629313\t[('0', 5)]\n",
      "NODE_103_length_116480_cov_9.513275\t[('0', 11)]\n",
      "NODE_412_length_23209_cov_8.227261\t[('3', 2)]\n",
      "NODE_340_length_31916_cov_8.031951\t[('3', 3)]\n",
      "NODE_119_length_103372_cov_9.464619\t[('0', 10)]\n",
      "NODE_328_length_33191_cov_16.589510\t[('2', 3)]\n",
      "NODE_48_length_202021_cov_9.674396\t[('9', 18), ('2', 2)], chosen: 9\n",
      "NODE_76_length_141953_cov_20.861915\t[('1', 14)]\n",
      "NODE_425_length_21404_cov_18.433697\t[('2', 2)]\n",
      "NODE_146_length_86396_cov_19.110168\t[('6', 8)]\n",
      "NODE_266_length_45776_cov_20.611754\t[('1', 4)]\n",
      "NODE_93_length_121423_cov_20.503213\t[('1', 12)]\n",
      "NODE_3_length_582236_cov_20.756519\t[('1', 57), ('7', 1)], chosen: 1\n",
      "NODE_423_length_21646_cov_8.094160\t[('3', 2)]\n",
      "NODE_16_length_364017_cov_19.173219\t[('3', 1), ('6', 35)], chosen: 6\n",
      "NODE_22_length_323290_cov_20.823837\t[('1', 32)]\n",
      "NODE_262_length_46351_cov_9.687921\t[('0', 4)]\n",
      "NODE_330_length_32885_cov_9.618550\t[('0', 3)]\n",
      "NODE_361_length_29184_cov_8.053418\t[('3', 2)]\n",
      "NODE_406_length_23540_cov_8.350522\t[('3', 2)]\n",
      "NODE_251_length_49707_cov_7.953355\t[('3', 4)]\n",
      "NODE_169_length_75964_cov_21.103255\t[('1', 7)]\n",
      "NODE_290_length_41285_cov_10.796119\t[('9', 4)]\n",
      "NODE_64_length_161415_cov_18.844236\t[('3', 1), ('6', 15)], chosen: 6\n",
      "NODE_319_length_34609_cov_16.197256\t[('8', 3)]\n",
      "NODE_180_length_69152_cov_9.754635\t[('0', 6)]\n",
      "NODE_408_length_23509_cov_18.021020\t[('2', 2)]\n",
      "NODE_370_length_27798_cov_18.335112\t[('2', 2)]\n",
      "NODE_181_length_69081_cov_16.313563\t[('8', 6)]\n",
      "NODE_369_length_27970_cov_15.845209\t[('2', 2)]\n",
      "NODE_275_length_43599_cov_15.736910\t[('8', 4)]\n",
      "NODE_295_length_39858_cov_7.751878\t[('3', 3)]\n",
      "NODE_29_length_262165_cov_19.548472\t[('6', 26)]\n",
      "NODE_190_length_67020_cov_9.650325\t[('0', 6)]\n",
      "NODE_26_length_268715_cov_9.559335\t[('9', 25), ('2', 1)], chosen: 9\n",
      "NODE_306_length_36958_cov_29.290112\t[('1', 3)]\n",
      "NODE_351_length_30294_cov_9.447931\t[('0', 3)]\n",
      "NODE_200_length_63453_cov_7.967538\t[('3', 6)]\n",
      "NODE_163_length_79622_cov_8.049958\t[('3', 7)]\n",
      "NODE_232_length_54655_cov_15.842473\t[('9', 1), ('2', 4)], chosen: 2\n",
      "NODE_167_length_78050_cov_16.052439\t[('8', 7)]\n",
      "NODE_313_length_35544_cov_15.865508\t[('2', 3)]\n",
      "NODE_278_length_42603_cov_16.038051\t[('8', 4)]\n",
      "NODE_316_length_35179_cov_16.799653\t[('2', 3)]\n",
      "NODE_344_length_31515_cov_16.526891\t[('8', 3)]\n",
      "NODE_410_length_23472_cov_20.747662\t[('1', 2)]\n",
      "NODE_160_length_80970_cov_17.449509\t[('2', 8)]\n",
      "NODE_287_length_41605_cov_10.370638\t[('9', 4)]\n",
      "NODE_414_length_23086_cov_7.766749\t[('3', 2)]\n",
      "NODE_327_length_33282_cov_9.583772\t[('9', 3)]\n",
      "NODE_170_length_74608_cov_9.643971\t[('0', 7)]\n",
      "NODE_63_length_165239_cov_19.283817\t[('6', 16)]\n",
      "NODE_75_length_142824_cov_20.624323\t[('1', 14)]\n",
      "NODE_8_length_445864_cov_16.022000\t[('8', 43), ('5', 1)], chosen: 8\n",
      "NODE_102_length_116504_cov_20.643518\t[('1', 10), ('7', 1)], chosen: 1\n",
      "NODE_31_length_242138_cov_19.014958\t[('3', 2), ('6', 22)], chosen: 6\n",
      "NODE_205_length_62075_cov_17.773589\t[('2', 6)]\n",
      "NODE_94_length_120390_cov_15.982989\t[('8', 12)]\n",
      "NODE_149_length_85102_cov_9.864534\t[('0', 8)]\n",
      "NODE_43_length_207403_cov_20.817905\t[('1', 20)]\n",
      "NODE_117_length_105047_cov_15.990609\t[('8', 10)]\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                                          splitting contigs into bins                                         -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Loading in the bins that the contigs belong to...\n",
      "Going through the entire assembly and splitting contigs into their respective bin file...\n",
      "Done!\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                               CONCOCT finished successfully, and found 11 bins!                              -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "########################################################################################################################\n",
      "#####                                   BINNING PIPELINE SUCCESSFULLY FINISHED!!!                                  #####\n",
      "########################################################################################################################\n",
      "\n",
      "\n",
      "real\t3m24.292s\n",
      "user\t10m20.882s\n",
      "sys\t0m28.170s\n"
     ]
    }
   ],
   "source": [
    "### We activate a metawrap conda environment and get going\n",
    "cd ~/data/MBGW223\n",
    "conda deactivate\n",
    "conda activate metawrap\n",
    "metawrap binning -o ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap -t 6 -a ./02_ASSEMBLY_BINNING/assembly_spades/contigs.fasta --metabat2 --maxbin2 --concoct ./00_READS/*.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb923468-3a44-407a-bba7-705be40a7e73",
   "metadata": {},
   "source": [
    "Used parameters:\n",
    "\n",
    "`-`: Output folder, `METAWRAP` will generate one folder with bins each, for `CONCOCT`, `MAXBIN2`, and `METABAT2`\n",
    "\n",
    "`-t`: We specify 6 threads to speed up the processing\n",
    "\n",
    "`-a`: The assembled contigs that should be used for the binning\n",
    "\n",
    "`--concoct`, `--maxbin2`, and `--metabat2`: Binning is done using these three tools\n",
    "\n",
    "If you check the defined output folder, you see the three output folders and you can see that the three tools identified different numbers of bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b65af861-87c2-4a10-8c04-22af3c6cf40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: cd: /home/lu87neb/data/MBW223: No such file or directory\n",
      "/home/lu87neb/data/MBGW223\n",
      "11\n",
      "9\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "### We count the number of bins in each output folder\n",
    "pwd\n",
    "ls ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/concoct_bins/*.fa | wc -l\n",
    "ls ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/maxbin2_bins/*.fa | wc -l\n",
    "ls ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/metabat2_bins/*.fa | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0719f8f7-670d-4cc1-a17f-16134e2a1e2c",
   "metadata": {},
   "source": [
    "Next we use `METAWRAP`s bin refinement module to consolidate the bins we obtained from `CONCOCT`, `MAXBIN2`, and `METABAT2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386507de-bda1-4bd5-a281-9043d59d62f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metawrap bin_refinement -o ./02_ASSEMBLY_BINNING/bin_refinement_spades_metawrap -t 6 -A ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/metabat2_bins/ -B ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/maxbin2_bins/ -C ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/concoct_bins/ -c 70 -x 10\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----            There is 40 RAM and 6 threads available, and each pplacer thread uses >40GB, so I will            -----\n",
      "-----                                          use 1 threads for pplacer                                           -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "########################################################################################################################\n",
      "#####                                                BEGIN PIPELINE!                                               #####\n",
      "########################################################################################################################\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "-----                               setting up output folder and copying over bins...                              -----\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "mkdir: cannot create directory ‘./02_ASSEMBLY_BINNING/bin_refinement_spades_metawrap’: No such file or directory\n",
      "\n",
      "************************************************************************************************************************\n",
      "*****                       cannot make ./02_ASSEMBLY_BINNING/bin_refinement_spades_metawrap                       *****\n",
      "************************************************************************************************************************\n",
      "\n",
      "\n",
      "real\t0m0.050s\n",
      "user\t0m0.017s\n",
      "sys\t0m0.033s\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "### Refining the bins\n",
    "cd ~/data/MBGW223\n",
    "conda activate metawrap \n",
    "metawrap bin_refinement -o ./02_ASSEMBLY_BINNING/bin_refinement_spades_metawrap -t 6 -A ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/metabat2_bins/ -B ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/maxbin2_bins/ -C ./02_ASSEMBLY_BINNING/initial_binning_spades_metawrap/concoct_bins/ -c 70 -x 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea129cff-b77c-48a5-8a5e-a37fa116307b",
   "metadata": {},
   "source": [
    "`METAWRAP` provides a very automated way for the binning. Several other tools allow \"human-augmented binning\", which usually makes use of differences in k-mer frequencies and differential coverage, and allows binning through visual inspection. Two examples are:\n",
    "\n",
    "* [`anvio`](https://anvio.org/)\n",
    "* [`VizBin`](https://github.com/claczny/VizBin)\n",
    "\n",
    "We touched `anvio` before when were estimating the number of bins in our assembly. We will use `VizBin` here because of its ease of use. You can download `VizBin` from the workshop folder `misc/VizBin.jar`. You have to also download the assembled contigs.\n",
    "\n",
    "![_Vizbin_ interface](img/vizbin1.png)  \n",
    "<font size=\"2\"> The _VizBin_ interface. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b4a5f5-ed69-455b-883f-1acf956f6878",
   "metadata": {},
   "source": [
    "We load our contigs into `VizBin`, leave all settings default, and press start. A new window should open (after few minutes, depends a bit on your laptop) and it should be full of blue dots (each blue dot represents one of our assembled contigs!).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>QUESTION/TASK:</b> \n",
    "<ul>\n",
    "  <li>Can you identify distinct populations of contigs? If yes, how many do you see?</li>\n",
    "  <li>PLEASE NOTE, our dataset is fairly easy to bin, in real life, a complex metagenome dataset looks a lot more messy!</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8595ac73-d1b4-438c-a071-7cf4f9168dda",
   "metadata": {},
   "source": [
    "<img src=\"img/vizbin2.png\" alt=\"Binning with VizBin\" width=\"500\"/>\n",
    "\n",
    "<font size=\"2\"> _VizBin_ k-mer based ordination of a complex metagenome. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0988e769-50a1-427c-b7f2-5a7da855cfdc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>QUESTION/TASK:</b> \n",
    "For binning distinct populations of contigs, we now proceed as follows:\n",
    "<ul>\n",
    "  <li>By left-clicking around a population you create a selection window.</li>\n",
    "  <li>After selecting a population right-click in the selection and export the selection (`Selection --> Export`), save the bins (e.g. bin1.fna) in a folder of your choice.</li>\n",
    "  <li>Clear the selection, `right-click --> selection --> clear and repeat`. Once you are done upload the bins to your data folder on the server.</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<sub> © Carl-Eric Wegner, 2023-08 </sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf2353a-c38c-4989-bd0b-fe5d9e380964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
